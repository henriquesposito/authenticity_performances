---
title: 'Radiating Truthiness: Authenticity performances in politics in Brazil and the United States'
output:
 pdf_document: default
 latex_engine: xelatex
 fig_caption: yes
 html_document:
 df_print: paged
fontsize: 12pt
mainfont: Times New Roman
header-includes:
  - \usepackage{floatrow}
  - \floatsetup[figure]{capposition=top}
  - \usepackage{float}
  - \floatplacement{figure}{H}
  - \usepackage[T1]{fontenc}
  - \usepackage[utf8]{inputenc}
  - |
    ```{=latex}
    \providecommand{\keywords}[1]{\textbf{Keywords:} #1}
    ```
  - |
    ```{=latex}
    \providecommand{\wordcount}[1]{\textbf{Word Count:} #1}
    ```
always_allow_html: TRUE
bibliography: references.bib
csl: chicago.csl
abstract: Political authenticity is connected to higher levels of political trust from electorates and can influence political outcomes but is often overlooked due to its alleged vagueness. When considered, discussions of how authenticity appears and changes in politics typically remain at the theoretical level and are rarely comparative. This article develops an original framework to identify and compare how authenticity is performed in political discourses over time, across settings, and by politicians. To demonstrate the usefulness of the framework, we investigate authenticity performances in 21496 political texts for electoral debates, interviews, campaigns, and official speeches for presidents and presidential candidates in Brazil and the United States (US) since 1988. The findings indicate that while authenticity is generally performed with greater frequency in Brazil than in the US, authenticity performances are not more prevalent during election years in both countries.
---

```{=latex}
\keywords{authenticity, performance, text analysis, populism, Brazil, United States}
```

```{=latex}
\wordcount{8400 (includes text, tables, figures, and notes)}
```

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(include = FALSE)
library(dplyr)
library(tidyr)
library(scales)
library(kableExtra)
library(tibble)
library(readxl)
library(ggplot2)
library(ggrepel)
library(readr)
library(stringr)
library(stringi)
library(ggthemes)
library(tm)
library(tidytext)
library(corrplot)
library(Hmisc)
library(ggpubr)
library(plm)
library(modelsummary)
library(stargazer)
library(geomtextpath)
library(RColorBrewer)
library(abdiv)
Sys.setlocale("LC_ALL", "C")
options(stringsAsFactors = FALSE, scipen = 999)
```

```{r data, message=FALSE, warning=FALSE, include=FALSE}
# # Since some of the text cleaning takes hours to run (i.e. removing punctuation),
# # we start with the data that has been merged and cleaned simple cleaning.
# # For more information on how the data was merged and the cleaning was done,
# # please see the analysis_descriptive script in the under the analysis folder.
# BR <- readRDS("BR.Rds") # Brazil data
# US <- readRDS("US.Rds") # US data
# # Let's create a length column based on number of words and characters for later
# BR$length <- str_count(BR$text, "\\w+")
# US$length <- str_count(US$text, "\\w+")
# BR$char <- nchar(BR$text)
# US$char <- nchar(US$text)
# # Let's also create a date (year) column for later on
# BR$year <- stringr::str_extract(BR$doc_id, "[0-9]{4}")
# US$year <- stringr::str_extract(US$doc_id, "[0-9]{4}")
# # Let's fix some names
# BR$doc_id <- gsub("Dilma", "Rousseff", BR$doc_id)
# BR$doc_id <- gsub("Aecio", "Neves", BR$doc_id)
# BR$doc_id <- gsub("FHC", "Cardoso", BR$doc_id)
# BR$doc_id <- gsub("Itamar", "Franco", BR$doc_id)
# US$doc_id <- stringr::str_trim(US$doc_id )
# US$doc_id <- gsub("Albert Gore, Jr.", "Gore", US$doc_id)
# US$doc_id <- gsub("Hillary Clinton", "H.Clinton", US$doc_id )
# US$doc_id <- gsub("Bill Clinton", "Clinton", US$doc_id )
# US$doc_id <- gsub("George W. Bush", "W.Bush", US$doc_id )
# US$doc_id <- stringr::word(US$doc_id, -1)
# # Let's get a speaker variable
# BR$speaker <- stringr::str_remove_all(BR$doc_id, "_[0-9]{4}")
# US$speaker <- stringr::str_remove_all(US$doc_id, "_[0-9]{4}")
# # Let' create a setting variable for when data is merged
# US$settingc <- paste0(US$setting, "_US")
# BR$settingc <- paste0(BR$setting, "_BR")
# # For the US and Brazil, let's subset the data for the years (e.g. 1988) and
# # politicians of interest...
# # Remove other speakers outside of the 2 years gap with the exception of Lula (for Brazil)...
# # # Brazil
# # Lula: 1988 to 2012 and from 2020 onwards
# # Color: 1988 to 1994
# # Franco: 1990 to 1996
# # Cardoso: 1992 to 2004
# # Serra: 2000 to 2004 & 2008 to 2012
# # Alckmin: 2004 to 2008
# # Neves 2012 to 2016
# # Rousseff: 2008 to 2018
# # Temer 2014 to 2020
# # Haddad: 2016 to 2020
# # Bolsonaro: from 2016 onwards
# # # US
# # Bush 1988 to 1995
# # Dukakis 1988 to 1990
# # Clinton 1990 to 2002
# # Dole 1994 to 1998
# # W.Bush 1998 to 2010
# # Gore 1998 to 2002
# # Kerry 2002 to 2006
# # Obama 2006 to 2018
# # McCain 2006 to 2010
# # Romney 2010 to 2014
# # H.Clinton 2014 to 2018
# # Trump 2014 to 2021
# # Biden from 2018
# BR <- BR %>% filter(as.numeric(year) > 1987, speaker != "Sarney",
#  speaker == "Lula" & year < 2013 |
#  speaker == "Lula" & year > 2019 |
#  speaker == "Collor" & year < 1995 |
#  speaker == "Franco" & year > 1989 & year < 1997 |
#  speaker == "Cardoso" & year > 1991 & year < 2005 |
#  speaker == "Serra" & year > 1999 & year < 2005 |
#  speaker == "Serra" & year > 2007 & year < 2013 |
#  speaker == "Alckmin" & year > 2003 & year < 2009 |
#  speaker == "Neves" & year > 2011 & year < 2017 |
#  speaker == "Rousseff" & year > 2007 & year < 2019 |
#  speaker == "Temer" & year > 2013 & year < 2021 |
#  speaker == "Haddad" & year > 2015 & year < 2021 |
#  speaker == "Bolsonaro" & year > 2015)
# US <- US %>% filter(as.numeric(year) > 1987, speaker != "Reagan",
#  speaker == "Bush" & year < 1995 |
#  speaker == "Dukakis" & year < 1991 |
#  speaker == "Clinton" & year > 1989 & year < 2002 |
#  speaker == "Dole" & year > 1993 & year < 1999 |
#  speaker == "W.Bush" & year > 1997 & year < 2011 |
#  speaker == "Gore" & year > 1997 & year < 2003 |
#  speaker == "Kerry" & year > 2001 & year < 2007 |
#  speaker == "Obama" & year > 2005 & year < 2019 |
#  speaker == "McCain" & year > 2005 & year < 2011 |
#  speaker == "Romney" & year > 2009 & year < 2015 |
#  speaker == "H.Clinton" & year > 2013 & year < 2019 |
#  speaker == "Trump" & year > 2013 |
#  speaker == "Biden" & year > 2017)
# # Dictionary of terms for authenticity performances for US
# truth_telling <- stringr::str_squish("am telling the truth|are telling the truth|is telling the truth|the truth is|this is the truth|not lying|not lies|no lies|not telling you lies|is honest|am honest|is being honest|are being honest|are honest|honesty|is sincere|are sincere|am sincere|is being sincere|are being sincere|is true|are true|not a liar|bottom of my heart|I swear|I reassure|we reassure|I assure|we assure|be assured|is truthful|are truthful|am truthful|is being truthful|are being truthful|I know that|is evident|are evident|I am sure|trust me|am frank|are frank|is frank|being frank|is upfront|are upfront|am upfront|being upfront|will come clean|am coming clean|are coming clean|is straightforward|are straightforward|being straightforward|believe me|I am certain|no bullshit|not bullshitting")
# lie_accusations <- stringr::str_squish("not truth|not the truth|not true|aren't true|isn't true|being untruthful|is lying|are lying|is a liar|are liars|is dishonest|are dishonest|being dishonest|is fake|are fake|being fake|is corrupt|are corrupt|full of lies|not sincere|not being sincere|isn't sincere|aren't sincere|not honest|not being honest|is cheating|is a cheater|are cheaters|are cheating|are tricking|is tricking|be deceived|is deceiving|are deceiving|are a hypocrite|is a hypocrite|are being a hypocrite|is being a hypocrite|is crooked|are crooked|is misleading|are misleading|has double-standards|are sneaky|is sneaky| has two faces|two-faced|has double faces|double-faced|you are wrong|not correct|fooled by|do not believe|is misrepresenting|they misrepresent|is misrepresent|are misrepresent|pretends that|pretends to|is pretending|are pretending|keep pretending|breach your trust|breach of trust|is false|are false|being false|is misinforming|are misinforming|being misinformed|pretended|cut the crap|full of crap")
# consistency <- stringr::str_squish("we delivered|I delivered|check and see|I keep my word|we keep our word|I kept my word|we kept our word|I keep my promise|I kept my promise|we keep our promise|as promised|we kept our promise|am responsible|I take responsibility|we take responsibility|we assume responsibility|we are accountable|we are responsible|our duty|my duty|give my word|giving my word|own up my|owning up my|accept responsibility|accept the blame|recognize my mistakes|admit I was wrong|I made mistakes|I guarantee|we guarantee|I can guarantee|we can guarantee|I promise|we promise|we can prove|I can prove|we proved|I proved|am reliable|rely on me|rely on us|be reassured|you can hold me accountable|you can hold us accountable|see with your own eyes|vote of confidence|our mission|my mission|my commitment|our commitment|during our government|during my government|while I was in charge")
# finger_pointing <- stringr::str_squish("are inconsistent|is inconsistent|being inconsistent|are irresponsible|is irresponsible|being irresponsible|their fault|not my fault|not our fault|they left us with|they are responsible|are not responsible|aren't responsible|is not responsible|isn't responsible|costed us|false promises|lack accountability|lacking accountability|not kept their word|not kept his word|not kept her word|not kept promises|not kept the|not kept his|not kept her|not kept their|not keep their word|not keep his word|not keep her word|not keep the|didn't keep the|didn't keep her|didn't keep his|hasn't kept his|hasn't kept her|not recognize|he made mistakes|she made mistakes|they made mistakes|not our mistake|not my mistake|not take responsibility|not my responsibility|not accountable|him accountable|them accountable|her accountable|blame them|blame him|blame his|blame her|their blame|break promises|broken promises|has betrayed|they betrayed|betraying|will betray|has tricked|has lied|not deliver|didn't deliver|hasn't deliver|failed your obligations|failed in your obligations|failed his obligations|failed her obligations|failed in his dut|failed in her dut|failed his dut|failed her dut|failed your dut|stabbed in the back")
# origins <- stringr::str_squish("I was born|I come from|we come from|I grew up|growing up in|my parents|my mom|my mother|my father|my dad|my family|raised me|I was raised|we were raised|we grew up|my background|being surrounded by|being exposed to|my siblings|going to school in|our local church|Sunday mass|Saturday mass|family tradition|tradition in my house|in our house|growing up|back in the day|my grandparents|in my town|in my state|in my region|our community|in my community|our town|our state|my hometown|our hometown|my home state|our home state|back home|our house|my house|our neighbourhood|in my district|I lived in|we lived in|we used to play|I used to play|I was thought")
# common_sense <- stringr::str_squish("is common sense|are common sense|everyone knows|it is undeniable|stating the obvious|say the obvious|everyone agrees|we all know|common wisdom|the people know|popular knowledge|from experience|it is my experience|sound judgment|practical solution|practical choice|practical answer|pragmatic solution|pragmatic answer|pragmatic choice|realistic answer|let me tell you about|is obvious|are obvious|obvious answer|obvious solution|as we all learned|we have all learned that|do not need to tell you that|the reality is|there is no logic|it does not make sense|it doesn't make sense|we know it does not work|no one disagrees that|no person disagrees|there is not a person|there is not a human being|there is not a family|there is not an American|there is no single citizen|there is not one single person|there is not one single human being|there is not one single family|there is not one single American|there is not one single citizen|there is not one single person|there is not one human being|there is not one family|there is not one American")
# anti_pc <- stringr::str_squish("politically correct|political correctness|PC|plain speaking|speaking my mind|speak my mind|say what I think|saying what I think|not going to pretend|not pretend|speak what you think|not what you want to hear|not butter up|not beat around the bush|cut to the chase|just being real|saying what everyone thinks|say what everyone is thinking|speaking plainly|colored people|negro|retarded|nigger|third world|oriental people|crippled people|is crippled|culturally deprived|drug addict|junkie|drunk|fat people|fat person|fat population|handicapped|homosexual|faggot|deviant|perverted|illegals|illegal immigrants|illegal alien|^jew$|^jews$|non-white|prostitutes|promiscuous|stupid|tribe|underdeveloped")
# territory <- stringr::str_squish("have been to|have visited|came all the way to|back from|will visit|saw first-hand|see first-hand|we visited|I visited|we visited|travelled to|traveling to|spend a few days in|spent some time in|spent time in|met great people in|we were hosted|I was hosted|our time in|my time in|our visit|spent a lot of time in|were many times in|got to know the whole country|got to know all the states")
# # Get each performance as frequencies per row, the (?i) makes it case insensitive
# US$truth <- stringr::str_count(US$text, paste0("(?i)", truth_telling))
# US$lies <- stringr::str_count(US$text, paste0("(?i)", lie_accusations))
# US$consistency <- stringr::str_count(US$text, paste0("(?i)", consistency))
# US$fpoint <- stringr::str_count(US$text, paste0("(?i)", finger_pointing))
# US$origins <- stringr::str_count(US$text, paste0("(?i)", origins))
# US$common_sense <- stringr::str_count(US$text, paste0("(?i)", common_sense))
# US$anti_PC <- stringr::str_count(US$text, paste0("(?i)", anti_pc))
# US$territory <- stringr::str_count(US$text, paste0("(?i)", territory))
# # Same dictionary but in Portuguese
# truth_telling <- ("a verdade e|esta e a verdade|digo a verdade|dizemos a verdade|pura verdade|não e mentira|não estou mentindo|e honesto|sou honesto|somos honesto|sendo honesto|a honestidade|ser sincero|e sincero|com sinceridade|e verdade|são verdadeiras|não sou mentiroso|não minto|fundo do meu coração|sou verdadeiro|somos verdadeiros|tenho certeza|certeza absoluta|confia em mim|confie em mim|pode confiar|sou franco|somos francos|fraqueza|falando a verdade|falo a verdade|falamos a verdade|acredite em mim|pode acreditar|podem acreditar|eu tenho certeza|isso e a verdade|somos honestos|com honestidade|toda a sinceridade|com sinceridade|toda sinceridade|sou confiável|somos confiáveis|as coisas são assim|a realidade das coisas|juro por deus|com certeza|digo com precisão|veracidade|premissa|afirmo para vocês|isso e como aconteceu|falar umas verdades")
# truth_telling <- stringr::str_squish(truth_telling) # removes unseen white spaces
# lie_accusations <- ("não e verdade|não e verdadeiro|e mentiroso|está mentindo|são mentiroso|e mentira|de mentira|tudo mentira|e desonesto|mentiram|mentiu|um desonesto|esse desonesto|de desonesto|são desonesto|e falso|são falsos|são corruptos|e corrupto|de corrupto|todos corrupto|não são sincero|não e sincero|não são honestos|não e honesto|são trapaceiros|e trapaceiro|eles trapaceiam|trapaceou|e enganar|ser enganado|vão enganar|sendo enganados|e hipócrita|e enganador|e enganação|duas caras|enganado por|não acredite|eles finge|ele finge|e fingimento|ela finge|quebrou a sua confiança |quebra de confiança| e falso|são falsos|falsidade|e ficção|história para boi dormir|historinha para boi dormir|e calunia|são calunias|difamação|difamar|uma inverdade|são inverdades|e inverdade|isso e invenção|essas são invenções|isso e uma lenda|essas são ledas|tenta iludir|tentando iludir|uma farsa|tramoia|mal intencionado|mas intenções|falta de informação|esta mal-informado|estão mal-informados")
# lie_accusations <- stringr::str_squish(lie_accusations)
# consistency <- ("nós entregamos|eu entreguei|veja com seus próprios olhos|cumpro minhas palavras|cumprimos nossas palavra|cumpri minha palavra|cumpro minhas promessas|nossas promessa|um compromisso|meu compromisso|tenho um compromisso com|eu sou responsável|eu assumo a responsabilidade|nós somos responsáveis|nós assumimos a responsabilidade|nosso dever|meu dever|dou minha palavra|faço uma promessa|fazer uma promessa|aceitar a responsabilidade|aceito a responsabilidade|aceitamos a responsabilidade|aceitar a culpa|meus erros|que errei|eu errei|eu garanto|eu posso garantir|eu prometo|podemos provar|posso provar|provaremos|eu provei|voto de confiança|encarrego pessoalmente|encarreguei pessoalmente|estou comprometido|meu comprometimento|comprometimento com|o comprometimento|fazer o possível|minha supervisão|minha missão|nossa missão|no meu governo|no nosso governo|durante nosso governo|eu era encarregado|eu era o encarregado|fomos encarregados de")
# consistency <- stringr::str_squish(consistency)
# finger_pointing <- ("e inconsistente|são inconsistente|e irresponsável|são irresponsáveis|culpa deles|a culpa não e minha|não e minha culpa|eles nós deixaram|são responsáveis|e responsável|nós custou|falsas promessas|falta de prestação de contas|falharam|falhou|não cumpriu|não cumpriram|não reconheceu|não reconheceram|errou|erraram|não se responsabiliza|não me responsabilizo|culpa e sua|sua culpa|quebrar promessas|promessas quebradas|quebra de promessas|fala uma coisa e faz outra|fala uma coisa aqui e faz outra|falsas promessas|são trapaceiros|cometeu erros|cometeram erros|não reconhece|não reconheceu|assumiu a responsabilidade|promete uma coisa|promete o mundo|traiu a confiança|traiu a sua confiança|quebra de confiança|quebraram sua confiança|e falcatrua|foi falcatrua|cheio de falcatrua|houve fraude|houveram fraudes|fraudulento|uma negociata|facada nas costas|faltou com respeito|não faz o que promete|não fez o que promete|promessas em vão|palavras em vão|falta de comprometimento|falta de compromisso|houveram desvio|houve desvio|a culpa e do|cheio de promessas|a conta não fecha|não terminaram")
# finger_pointing <- stringr::str_squish(finger_pointing)
# origins <- ("Eu nasci|Eu vim de|eu venho de|viemos de|cresci|nós crescemos|meus pais|minha mãe|minha mãe|minha família|fui criado|fomos criados|minhas origens|meus irmãos|meu irmão|minha irmã|tradição familiar|tradição em casa|crescendo|antigamente|meu avô|minha avó|meus avós|na minha cidade|no meu estado|na minha região|nossa comunidade|na minha comunidade|nossa cidade|nosso estado|cidade natal|estado de origem|minha casa|nossa casa|lá em casa|nosso bairro|no meu bairro|eu morava|vivíamos|na minha terra|de onde eu venho|missa de domingo|missa toda semana|brincava|eram outros tempos|fui educado|morávamos|eu morei|nós moramos|de onde venho|eram tempos diferentes")
# origins <- stringr::str_squish(origins)
# common_sense <- ("senso comum|bom senso|todos sabem|afirmando o óbvio|todos concordam|todos sabemos|sabemos todos|todos nós sabemos|sabedoria popular|por experiência|e minha experiência|sou prático|tem que ser prático|devemos ser prático|sendo prático|sou pragmático|tem que ser pragmático|devemos ser pragmático|sendo pragmático|sou realista|sendo realista|sejamos realista|realisticamente falando|e óbvio|como todos nós aprendemos|como sabemos|não preciso te dizer|o povo sabe|agente aprendeu|nós aprendemos|nós sabemos|não tem logica|como aprendemos|não faz sentido|não fazem sentido|estamos cansados de saber|sabemos que não funciona|ninguém discorda que|não tem uma pessoa|não existe uma pessoa|não há uma pessoa|não existe um ser humano|não tem um ser humano|não há um ser humano|não tem uma família|não existe uma família|não há uma família|não tem um brasileiro|não há um Brasileiro|não existe um brasileiro|não tem uma brasileira|não há uma Brasileira|não existe uma brasileira")
# common_sense <- stringr::str_squish(common_sense)
# anti_pc<- ("politicamente correto|falar francamente|falando francamente|falar o que penso|falo o que penso|falando o que penso|dizer o que penso|papas na língua|não vou fingir|não estou aqui para agradar|falar o que você pensa|o que você quer ouvir|não adulterar|não rodeio|não dou rodeio|direto ao ponto|dizer o que todos pensam|dizendo o que penso|dizendo o que todos pensam|dizer o que todos estão pensando|não vou amaciar|não dá para amaciar|gordos|retardado|retardada|veado|população preta|os pretos|as pretas|terceiro mundo|viciado em drogas|bêbado|drogado|sem cultura|pervertidos|promíscuo|imbecil|estupido|aleijado|defeituoso|incapacitado|inválido|mongoloide|deficiente mental|deficiência mental|o incapacitado|a incapacitada|travesti|homossexualismo")
# anti_pc <- stringr::str_squish(anti_pc)
# territory <- ("estive em|visitei|voltou de|voltei de|voltando de|voltamos de|estive em|estivemos em|visitará|visitarei|vi em primeira mão|ver em primeira mão|visitamos|viajei para|passei alguns dias em|passei algum tempo em|passei um tempo|conheci ótimas pessoas|conhecemos ótimas pessoas em|fomos hospedados|minha passagem|nossa passagem|nossa visita|fui muitas vezes para|estive muitas vezes em|passei muito tempo em|meu tempo em|estive por todo o Brasil|de norte a sul do pais|conheço todo o pais|conheci todo o pais|conheci todo o Brasil|conheço todo o Brasil")
# territory <- stringr::str_squish(territory)
# # Get each performance as frequencies per row, the (?i) makes it case insensitive
# BR$truth <- stringr::str_count(BR$text, paste0("(?i)", truth_telling))
# BR$lies <- stringr::str_count(BR$text, paste0("(?i)", lie_accusations))
# BR$consistency <- stringr::str_count(BR$text, paste0("(?i)", consistency))
# BR$fpoint <- stringr::str_count(BR$text, paste0("(?i)", finger_pointing))
# BR$origins <- stringr::str_count(BR$text, paste0("(?i)", origins))
# BR$common_sense <- stringr::str_count(BR$text, paste0("(?i)", common_sense))
# BR$anti_PC <- stringr::str_count(BR$text, paste0("(?i)", anti_pc))
# BR$territory <- stringr::str_count(BR$text, paste0("(?i)", territory))
# rm(list=ls()[! ls() %in% c("BR", "US")])
# # The above was saved as data to speed up the markdown knitting time.
# # It was left here for reproducibility.
BR <- readRDS("BR_coded.rds")
US <- readRDS("US_coded.rds")
```

# 1 Introduction

Political authenticity, as the perceived degree to which politicians appear to remain true to themselves [@luebke2022], is connected to higher levels of political trust from electorates [@stiers2021; @valgarosson2021] and is essential for a candidate's success [@alexander2010; @fordahl2018]. Perceptions of authenticity inform electorates about how politicians might act in contexts where the public is absent, giving them a compelling reason to choose certain politicians [@jones2016]. Yet, authenticity is frequently overlooked as a determinant factor for electoral behavior for being deemed vague and contradictory as a concept [@varga2013]. When considered, discussions of how, when, and where authenticity appears and changes in politics usually remain at the theoretical level and are rarely comparative. This article develops an original framework to identify and compare how authenticity has been performed in politics over time, across settings, and by politicians.

Politicians perform authenticity discursively by making self- references to their origins, using narratives of consistency, alluding to civic traditions, disclosing personal details, and using 'vulgarism' [@fordahl2018; @luebke2021; @alexander2010]. Building on these insights, this article develops the authenticity performance framework that focuses on the mechanisms and shared discursive displays help build authenticity perceptions. Authenticity performances are divided into two categories, about the self or about belonging. The former derive plausibility from the performers themselves and include claims of truth telling, lie accusations, taking responsibility for actions, and pointing fingers at other politicians' mistakes. The latter derive plausibility from the shared cultural knowledge connecting politicians and audiences. These performances include references to origins, allusions to common sense, assertions of territorial knowledge, and use of vulgarism.

To demonstrate the usefulness of the framework, this article investigates authenticity performances in 21,496 political texts of electoral debates, interviews, campaigns, and official speeches for presidents and presidential candidates in Brazil and the United States (US) since 1988. Authenticity performances are identified via a purpose-built dictionary of terms that codes the displays associated with each performance theorized by the framework. The two countries, Brazil and the US, experienced a racialized nation building processes that led to heterogenous demographic compositions and cultural influences but different types of socioeconomic inequalities [@marx1998]. Currently, the two countries are federal presidential democracies in which presidents formally and informally shape the public policy agenda [@morgenstern2013; @pereira2008]. Though Brazil's extremely fragmented multiparty system stands in sharp contrast to the US two party system [@mainwaring1991; @mainwaring1999; @baker2020]. Considering the similarities and differences in the two cases, comparisons are careful and contextualized to provide useful insights.

The findings indicate that authenticity is not performed more frequently in election years. Authenticity is generally performed with greater frequency in Brazil than in the US. Brazil's party fragmentation and weak partisanship provide incentives for politicians to display individualistic behavior that might include performing authenticity more often and in more diverse forms across settings, in comparison to the US where politicians are typically more constrained by their parties. In both countries debates have recently become the setting in which authenticity is performed most frequently, whereas interviews are the setting in which authenticity is performed least frequently. Debates are large scale media events that produce “sticky” sound and visual bites charged with imagery that circulate more than ever in democracies. Relatedly, social media platforms give politicians diverse outlets to interact directly with audiences, bypassing journalists in interviews. In the US, presidential candidates perform authenticity more frequently than elected presidents while, in Brazil, authenticity is performed at comparable rates independent of a politicians' role. In both cases, presidential candidates' tend to perform multiple types of authenticities but, once elected, presidents likely learn from what types of performance “stick” and adapt to perform only the authenticities that work for them. 

This article lays down the foundations for comparative research on authenticity in politics. Conceptually, this article provides the first framework for identifying and comparing diverse performances of authenticity in politics. Empirically, besides the sizeable datasets of political texts for presidents and presidential candidates, this article provides the first comparative overview of how, where, and when authenticity has been performed in politics in in Brazil and the US since 1988. In what follows, this article is organized in four sections. The theoretical section discusses the literature on performance and authenticity in politics as well as presents the authenticity performances framework. The methodological section examines the comparison between Brazil and the US and describes the data gathering process and operationalization of the framework. The analytical section provides a visual and descriptive review of the findings. The article concludes by discussing the implications of using the authenticity performances framework and providing directions for further research.

# 2 Theory

## 2.1 Performing authenticity in politics

To be elected or remain in power, politicians must convince electorates that they will represent them in office. Democracy entails an institutional arrangement in which few individuals “acquire the power to decide by means of a competitive struggle for the people's vote” [@ricci1970]. Electoral rules and social heterogeneity influence politicians’ behaviors [@neto1997; @grofman2004; @samuels2010]. Electoral systems with multiple parties and where the head of government is directly elected can, for example, be more conducive to autonomous behavior by politicians that diverse from their parties [@mainwaring1997]. Though politicians also act autonomously in two-party or proportional representation systems [@riker1982], particularly in cases where parties become organized around a single politician [@garzia2022]. Politicians' behavior varies beyond the electoral systems and institutional environment they are inserted [@siavelis2008; @grofman2004] and the public policy positions they hold [@nai2021; @grofman2004]. In fact, politicians employ several material and discursive strategies to attract and maintain electoral support. These strategies range from producing television commercials and directing regional investments to making campaign promises and bonding with electorates. Many of which can be contradictory and do not have direct policy implications but, nonetheless, still matter for electoral outcomes.

Political discourses are fundamental to establish a connection between politicians and electorates, yet we know little about how politicians relate to electorates when speaking to them [see @lobo2014]. Political scientists regularly investigate how argumentative logics and issue framings affect persuasion and lead to changes in attitude in electorates for certain public policy issues [see @schmidt2001; @schmidt2002; @leruth2019]. However, beyond basic demographic characteristics as age, gender and race, political scientists have largely sidelined how perceptions of politicians' personalities matter for political engagement, discussion, and electoral decisions [@greenstein1992; @hibbing2011; @valgarosson2021]. Even when scholars look at politicians' personas, they usually do so for a single politician over time or focus exclusively on perceptions of politicians' competencies [see @catellani2015; @cwalina2016]. The personification of political parties and the increased attention audiences pay to the private lives of politicians, changed politicians' relationship to electorates and made their perceived personality essential to electoral decisions [@catellani2015].

Being perceived as authentic helps politicians build political trust by demonstrating to electorates that they are in touch with ordinary people and their struggles [@valgarosson2021; @stiers2021]. @taylor1992 argues that authenticity is a modern ideal related to being in touch with one's “original” inner self. Contemporary societies value this to achieve self-fulfillment [@taylor1992]. The modern ideal of authenticity also generates a widespread fear of the “replica”, the inauthentic [@varga2013]. Authenticity, albeit frequently sidelined for being contradictory and vague as a philosophical concept, shapes how we relate to ourselves, our goals, and others [@varga2013; @taylor1992]. In politics, authenticity concerns appearing coherent with individual or societal values to radiate truthiness outwards [@valgarosson2021; @fordahl2018; @alexander2006]. Hence, political authenticity is understood as the perceived degree to which politicians appear as being and remaining true to themselves [@luebke2022] ^[I refrain from discussing the sources, and ethics, of authenticity [see @taylor1992] or how the ideal of authenticity relates to aesthetics, autonomy, and capitalism [see @varga2013]. Authenticity, for the purposes of this piece, is an important modern individual ideal that is evoked, searched, and performed in politics.]. Perceptions of authenticity inform electorates about how politicians might act in contexts where the public is absent and unable to influence decisions, giving them a compelling reason to choose certain politicians [@jones2016]. This does not mean authenticity is static or constant in politics. Rather, authenticity is an unstable and malleable performance that demands constant contortion and repetition [@fordahl2018]. Authenticity is an integral part of a successful performance and is constantly performed in politics.

Performances are the projections of a situation when one appears before others, “however passive their role may seem to be, will themselves effectively project a definition of the situation by virtue of their response to the individual” [@goffman1956, p. 3]. Performances allow to theorize that an audience's interpretation hinges on factors beyond discursive content or a specific interpretation of message meaning, such as how things are said [@alexander2006; @alexander2011]. Performances place agency both with electorates, watching and evaluating politicians, and with political performers “doing” politics [@alexander2006, p. 35; @dijk1997]. This means script changes can be theorized to be intentional individual innovations or unintentional chattering by political performers, while political accomplishments reflect positive evaluations from electorates. Other factors like gender, race, role, economic crises, and cultural changes, become collective background representations to be explored in discursive politics and provide context for audiences' interpretations [@alexander2006, p. 46; @alexander2011]. Background representations shape politicians' performances and audiences' perceptions of authenticity. Incumbents' competence levels, for example, are perceived differently by electorates in comparison to non-elected candidates; something politicians are aware of, help construct, and perform when doing politics [see @cwalina2016]. Alternatively, belonging to a minority can influence how politicians perform to “authentically” belong in society [see @alexander2010]. Moreover, gender expectations constrain performances and audience perceptions of authenticity in politics [@goren2018] compelling to perform politics in different ways than man by disclosing more of personal details, using distinctive types of anecdotes, and justifying choices with concrete reasoning [@wood1994; @christine2005; @blankenship1995; @franceschet2016]. 

## 2.2 Authenticity performances, a framework

All politicians perform authenticity to connect with audiences. Politicians perform authenticity discursively by making self-references to origins, using narratives of consistency, telling remarkable stories, alluding to civic tradition, disclosing personal details, and using 'vulgarism' [@fordahl2018; @luebke2021; @alexander2010; @seifert2012]. Authenticity in politics is mediated by intermediary channels (e.g. the news) and perceived by audiences [@luebke2021]. Capturing how authenticity is mediated or perceived by certain audiences is not possible looking only at texts of political discourses. Besides, politicians' ability to “fuse” performances of authenticity and radiate truthiness outwards is ultimately bound by audiences' interpretations [@alexander2006]. However, by shifting our understanding of authenticity beyond a measure of performative success [see @alexander2006, p. 55] to a performance itself, even if this performance does not radiate truthiness, we can develop a framework that allows us to identify and compare authenticity performances.

Different politicians perform authenticity in specific ways, but these performances normally share certain discursive patterns. The framework of authenticity performances focuses on mechanisms and displays. Mechanisms refer to theorized pathways by which a discursive display could produce authenticity perceptions. Displays refer to the common elements connecting similar performances. While the theoretical literature on authenticity [see @luebke2021; @alexander2006] and case studies for diverse politicians [see @alexander2010; @fordahl2018] mention performances of authenticity, these are usually attached to a single politician or detached from actual politicians. By regrouping these dispersed manifestations according to their mechanisms, we can analytically identify patterns in the discursive displays associated with them. When politicians' recount stories about their origins, for example, they habitually signal that this is a story about origins by saying “when I was little” or “growing up”. The displays indicated in the framework allow to systematically identify and compare authenticity performances in politics.

Authenticity performances can be broadly divided in two categories: about the self and about belonging. These categories relate to the the plausibility of a certain performance. Authenticity performances about the self derive plausibility for performance from expectations about the political performer himself/herself (or their opponent). In their most basic form, these performances include stating to be telling the truth, to be authentic, or claiming others are lying, are inauthentic. These performances can make politicians appear truthful regarding their beliefs and/or more sincere vis-a-vis others. Authenticity performances about the self can also be performed with claims of consistency or by pointing fingers at others. Taking responsibility for one's previous actions along with their positive or negative outcomes might illustrates how a politician is consistent with promises. Alternatively, by pointing fingers at others' errors or broken promises, politicians argue for the others' lack of accountability based on previous actions.

Authenticity performances about belonging are displays of authenticity that derive plausibility for performance based on the cultural connections shared between audiences and political performers. These performances are essential to connect politicians to ordinary individuals and legitimize politicians as part of society and their knowledge about the “real” issues people in their country face. Authenticity performances about belonging include, for example, allusions to the politician's common origins that demonstrate their cultural connection to the nation. Origin performances include references to their own beginnings, how they were raised, and civic traditions. Politicians can also establish they authentically belong by alluding to shared common sense, which implies they reason like the rest of the population. Additionally, politicians can show their knowledge of the territory to demonstrate that they understand the nation and the regional differences. Finally, politicians can perform vulgarism to express that “they say what they think”. Vulgarism, as an authenticity performance, includes references to speaking without filters, as they see fit, and anti-politically correct discourses. Employing vulgar, politically incorrect, language in politics can make political communicators appear less strategic and more genuine [@rosenblum2020; @conway2017; @conway2009] ^[Anti-politically correct discourses employ politically incorrect language and/or denounces political correctness. In fact, denouncing of a “PC politician” engrains an allusion to someone that expresses its views in calculated ways to avoid judgment [@hughes2011; @weigel2016]. Politically incorrect expressions coded in dictionary and displayed in table 1, below, were selected from a 1992 dictionary of politically correct language. This assumes that most of the terms coded have minimally been agreed upon as not PC (see Beard and Cerf 1993).]. Table 1, below, summarizes each authenticity performance, their category, displays, and mechanism.

````{=tex}
\begin{landscape}
```{r Table 1, fig.cap="Authenticity Performances, Mechanisms, and Displays", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE}

table1 <- tibble::tibble("Authenticity Performance" = c("Truth Telling", "Lie Accusations", "Consistency ", "Finger Pointing", "Origins", "Common Sense", "Territory", "Vulgarism"),
Category = c("Self", "Self", "Self", "Self", "Belong", "Belong", "Belong", "Belong"),
Mechanism = c("Politician appears to be telling the truth regarding their beliefs or facts", 
"Politician appears more sincere vis-a-vis others", 
"Politician appears consistent regarding pledges", 
"Politician appears not accountable for previous undesirable outcomes", 
"Politician seems culturally connected to the nation", 
"Politician seems to make choices consistent with what others in society would do",
"Politician seems territorially connected to sub-regions, regions, or nation",
"Politician seems to be saying what they think without thinking about the consequences"),
"Displays" = c("Mentions truthfulness, sincerity, and/or honesty when describing oneself. Examples: 'the truth is', 'this is the truth', 'am not lying', 'is/are/am honest'",
"Mentions dishonesty, untruthfulness, and/or insincerity when used to describe others. Examples: 'not the truth', 'not true', 'untruthful', 'is/are lying', 'is/are liars'",
"Mentions career consistency, responsibility, and/or accountability for individual. Examples: 'I/we delivered', 'check and see', 'keep my word', 'I/we take responsibility'",
"Mentions lack of accountability, inconsistency and/or blame others for mistakes. Examples: 'are/is inconsistent', 'are/is irresponsible', 'their fault', 'costed us'",
"Alludes to birthplace, origins, and roots to describe background, values, and/or tell their story. Examples: 'I was born in', 'I was raised', 'I/we grew up in', 'my family'",
"Alludes to common sense, reason, and/or logic to describe choices or preferences. Examples: 'is/are common sense', 'everyone/everybody knows', 'it is undeniable', 'stating the obvious'",
"Alludes to sub-portions of the territory known and/or visited. Examples: 'have seen in', 'have been to', 'I/we/have visited', 'came all the way to'",
"Alludes to saying what they really think, talking without filters and/or employs anti-politically incorrect language. Examples: 'speak/speaking my mind', 'say/saying what everyone thinks', 'not politically correct', 'colored/oriental/fat/handicapped people'"))

kbl(table1, booktabs = TRUE, longtable = TRUE, caption = "Authenticity Performances, Categories, Mechanisms, and Displays") %>% kable_styling(latex_options = c("striped", "repeat_header"), font_size = 10, full_width = TRUE) %>% column_spec(1, width = "3.5 cm", bold=TRUE) %>% column_spec(2, width="3 cm") %>% column_spec(3, width = "4 cm") %>% column_spec(4, width = "10 cm")
```
\end{landscape}
````

Authenticity performances projected by politicians with diverse roles (e.g. candidates versus elected officials), across different the settings where politics gets done (e.g. debate or official speech), and at different times (e.g. before/after an election), among other things. These provide important expectations about how each of these background representations affect authenticity and guide patterns to be investigated in political discourse. How projections of authenticity change according to a politicians' role, setting, and time provide a helpful pathway to identify and compare how politicians perform authenticity when doing politics over time, across settings, and by politicians.

# 3 Methodology

## 3.1 Case selection: Brazil and the US

The role of authenticity in politics caught public attention after the elections of Trump, in the US, and Bolsonaro, in Brazil [see @fordahl2018; @kohl2021]. However, authenticity has long been central to presidential elections in both countries. In the US, Ronald Reagan's unusually colloquial speech patterns and folksy storytelling helped him come across as familiar, trustworthy, and authentic to electorates [@seifert2012]. Barack Obama often alluded to his origins and civic traditions to connect with audiences and generate a sense of authenticity [@alexander2010]. Donald Trump's authenticity was built through iconic brakes with political conventions, willingness to engage in controversial topics, and vulgar representations of American traditions from his “straight shooter dealmaker” persona [@fordahl2018]. In Brazil, Fernando Collor's persistent usage of religious metaphors made him appear trustworthy to electorates for upholding shared religious and moral principles [@tavares1998]. Luiz Inacio Lula da Silva (Lula)'s perceived authenticity often revolved around his ability to construct himself as a regular working-class man by constantly recounting his personal story using the “people's” language [@french2022]. Jair Bolsonaro's usage of vulgar, direct, and contradictory comments on moral issues, helped him appear as a simple and authentic “family man” to electorates [@feres2021; @carlo2018]. Yet, each of the accounts above focuses on specific authenticities performed by a single politician in selective samples of political discourses. Without a framework to identify and compare authenticity systematically we do not know, for instance, whether Trump or Bolsonaro performed authenticity more frequently or in significantly different ways than other politicians in Brazil and the US. 

Brazil and the US experienced racialized nation building processes that led to heterogenous demographic compositions and cultural influences, but different types of socioeconomic inequalities [@marx1998]. Both countries held the world's largest enslaved populations until slavery was abolished in each country respectively. Brazil and the US later became settler states for hundreds of thousands of European migrants throughout the 19th and 20th centuries. Nevertheless, previous comparative studies on race often relied on misguided narratives of racial democracy and integration that masked how, and the extent to which, race and racism was historically dealt with and prevails in Brazil in comparison to the US [@silva2020]. Additionally, there were considerable differences in the travel subsidies and assimilation incentives offered to migrant groups in these two countries [@balderas2010]. While there are geographical, historical, and cultural similarities between Brazil and the US, each country should be understood as a configuration, formed by the aggregation of parts that make sense in their context [@ragin1987]. This means, in practice, comparisons between the two countries must be careful and contextualized to avoid misled associations and provide useful insights.

Although Brazil and the US have different electoral systems, both countries are federal presidential democracies where presidents are the primary players formally, and informally, shaping the public policy agenda [@morgenstern2013; @pereira2008]. Brazil's extremely fragmented multiparty electoral system gives politicians strong autonomy, contributes to weak political parties, and incentivizes individualistic behavior from politicians [@mainwaring1991; @mainwaring1999; @baker2020]. With many weak parties, politicians in Brazil are less susceptible to broad pressure to conform and represent interests of parties in comparison to the US electoral system with two major parties. Moreover, the US has been a relatively stable democracy and considered a democratic innovator for over two centuries [@markoff1999] whereas democracy came back to Brazil in 1985 after decades of a military dictatorship. The Brazilian constitution of 1988 implementing what is referred to as a “coalitional presidentialist” political system [@couto2021]. This provides interesting contrast since, in Brazil, presidents are relatively autonomous from their parties to act but must form broad party coalitions to govern while, in the US, presidents are more accountable to their parties but do not have to form a coalition to govern. 

The late-1980s marked a turn in democratic politics where the spread and diversification of mass media revealed unprecedented levels of information about politicians' private lives changing their image, presentation, and perceptions [@seifert2012]. For the first time, politicians were able to reach and interact with the masses regularly in direct and immediate ways, making political communications resemble a state of permanent campaigning [@blumler1999; @voltmer2004]. In the US, Ronald Reagan 's presidential terms introduced the “primetime presidency” where television gradually became a means of governing and personality perceptions as important as political program [@denton1988]. In Brazil, Fernando Collor's sudden rise in the 1989 election, the first direct presidential election after the end of the military dictatorship, is attributed to his ability to communicate well on television during the campaign, rather than party affiliation, political capital, or policy program [@gibson1992]. Even as audience perceptions about politicians' personality increasingly important since the late-1980s in Brazil and the US, scholars have paid relatively little attention to how authenticity appears and changes in these two countries until recently.

## 3.2 Data and Operationalization

Text data for discourses of runoff presidential candidates across official speeches, campaigns, debates, and interviews were gathered from 1988 to 2021 for Brazil and the US. Runoff candidates, in the case of the US, represent the democratic and republican nominees in a presidential election ^[Data on vice-presidents (e.g. Biden or Temer when vice-president), other influential third-party candidates (e.g. Ross Perot in 1992; Marina Silva in 2010 and 2014), or candidates not nominated (e.g. Bernie Sanders in 2016) were not gathered for consistency. Gathering data for presidents and runoff candidates only also renders the number of politicians for both cases comparable with 13 politicians in the case of the US and 11 for Brazil.]. In the case of Brazil, runoff candidates represent the two candidates that compete in the second round of presidential election ^[When election was decided in the first round in Brazil, texts for the two leading candidates in the first round were selected.]. Restricting the sample to runoff candidates helps to avoid that relatively small samples of texts for less relevant candidates in a election skew the subsequent findings. The year of 1988 was chosen to be the cutoff date since it was an election year in the US and the year in which the current Brazilian constitution entered into force. This choice reflects the fact that covering the same period for both countries facilitate comparisons. 

Settings represent the various venues where the dialogue between the public and a politician occurs, beyond official speeches [@seifert2012]. The official speeches setting includes text data for all speeches elected presidents delivered while in office. The debates setting includes text for debates after party nominations in the US and second round debates for Brazil ^[There are a few exceptions to this in Brazil when elections decided in the first round (e.g. 1994) or candidates were unable to participate in runoff debates (e.g. Bolsonaro in 2018). In these cases, the participation of the two most voted candidates in the first-round debates were gathered. Since there can be multiple politicians in a debate, the text of each debate was separated by politicians for analysis.]. The campaigns setting includes text from campaign rallies and campaign commercials up to two years before elections runoff candidates participated in. The interviews setting includes text for interviews provided to traditional news media outlets (i.e. television, newspapers, and magazines) for the period of two years around (i.e. prior and after) election years for runoff candidates not elected. For elected presidents, interviews were gathered two years before, during the time they held office, and two years after they left office ^[Lula has been present in all elections in Brazil from 1989 to 2006. Therefore, data for him was consistently gathered from 1988 to 2012 and from 2018 onwards. This also helps explain why Brazil has a slightly smaller number of politicians in sample in comparison to the US.]. Beyond accounting for different settings, this approach allows to compare elected presidents and non-elected presidential candidates before/during elections, when in office for those elected, and after office or elections took place. Table 2, below, lists the politicians and the number of text observations by setting for each case. In total, 21496 political texts were gathered for Brazil and the US.

```{r table 2, echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE}
# For more info on observations, please refer to "total_obs.R" file in the data folder.
table2 <- tibble::tibble("Country" = c("", "US", "", "",
                                       "", "Brazil", "", ""),
  "Politicians" = c("Bush, Dukakis, Clinton, Dole,",
                    "W. Bush, Gore, Kerry, McCain,",
                    "Obama, Romney, H. Clinton, Trump,",
                    "and Biden",
                    "",
                    "Collor, Lula, Franco, Cardoso,",
                    "Serra, Alckmin, Rousseff, Neves,",
                    "Temer, Haddad, and Bolsonaro"),
  "Setting" = c("Speeches", "Campaign", "Debates", "Interviews",
                "Speeches", "Campaign", "Debates","Interviews"),
  "Observations" = c(12866, 1545, 24, 829, 5782, 175, 258, 17))
kbl(table2, booktabs = T, caption = "Text Data for Brazil and the US") %>%
 kable_styling(latex_options = "HOLD_position", bootstrap_options = "striped") %>%
 column_spec(1, bold=TRUE)
```

Texts for the US were scraped from The American Presidency Project repository (TAPP). The repository contains the most complete data on American presidents and presidential candidates available. Collecting data for Brazil, instead, was more challenging due to lack of one central repository. For official speeches, @silva-muller2023 dataset containing all official speeches for Brazilian presidents since 1985 was used. Text for debates, interviews, and campaigns for Brazil were scraped from subtitles automatically generated for YouTube videos. The number of videos available for later election cycles, especially after the 2000s, is considerably larger than earlier ones. Additionally, some election cycles in Brazil were shorter due to a candidate winning in the first round, limiting the number of texts available for these election cycles. For these reasons, the number of observations in the text datasets for the US is greater than for Brazil ^[For all the data, scripts, and additional replication materials please contact the author for access to the authenticity performances repository available on GitHub.]. After collection, texts were cleaned by removing punctuations and accents.

Authenticity performances were operationalized via a purpose-built dictionary of terms that codes the discursive displays associated with each performance in framework (see Codebook in Appendix). The dictionary of terms for each of the theorized authenticity performances was inductively developed listening to samples of randomly selected speeches, campaigns, interviews, and debates from the datasets. To enable comparisons, the dictionary has similar definitions in Portuguese and English in relation to the words and expressions searched for. The number of words included in the dictionary for each performance is also similar across languages. The dictionary of terms is designed to reduce the possibility of overlaps, even as some authenticity performances might share similar displays. Directionality in the text is important to identify authenticity performances that talk about themselves or others, thus, no stop words are removed from texts. This means the dictionary of terms includes combinations of pronouns/determiners and verbs/nouns to avoid false-positive matches for authenticity performances. 

Since the frequencies of authenticity performances can reflect the quantity of texts collected for a certain case, year, setting, or politician, the frequencies of authenticities performances are normalized for the total number of words in the texts they appear in by year. Normalization facilitates comparisons between Brazil and the US even as the number of observations within and between the two cases differs. In practice, normalization helps to account for differences in observations for different years, between settings per years, or for disparities among politicians who held multiple mandates in comparison to candidates who appeared in a single election cycle. The normalized scores represent the proportion of words associated to one or more authenticity performances in relation to the total of words in a year, by setting per year, or by politician per year. The scores were multiplied by one thousand to facilitate interpretation, they represent the normalized proportion per 1,000 words.

The focus of the forthcoming analysis section is descriptive on how, where, and when authenticity is performed in Brazil and the US. Nevertheless, the analysis employs fixed-effects regression models to explore the relationship between authenticity performances and politicians' roles. That is, when politicians perform authenticity and how. The models are indexed by year, as events that take place for each case in a certain year can affect authenticity performances. Additionally, as politicians interact, imitate, and respond to one another at any given year, they can influence when and how authenticity is performed. Fixed effects models help to control for year specific and other unseen unit-unvarying characteristics [@allison2009]. The dependent variables for models are the total frequency of authenticity performances or the diversity scores for authenticity performances. Diversity scores are calculated using the Herfindahl–Hirschman index of concentration where scores closer to 0 represent a variety of authenticity performances occurring at similar rates and scores closer to 1 represent concentrated performances around a single type of authenticity [see @rhoades1993] ^[The Herfindahl–Hirschman index (HHI) can be used to measure concentration or diversity in a variety of contexts ranging from income to market monopolies. The score is calculated by adding the squared scores of each authenticity performances.]. The independent variables reflect the politicians' roles as “candidates” (i.e. runoff candidates or presidents before being elected a first time), “in office” (i.e. elected presidents during time they held office), and “after office” (i.e. denotes elected presidents after they leave office) ^[When running from re-election from office, incumbents are also coded as being in office.]. Since politicians' behaviors can be affected by their party, ideology, and other institutional constraints, we control for politicians' political party ^[For Brazil, politicians were divided into the Workers Party (PT), the Partido da Social Democracia Brasileira (PSDB), and other parties since most politicians in the sample belong to PT or PSDB. The “other parties” category includes politicians from additional parties (e.g. Temer) and/or that changed parties during their presidency (e.g. Itamar Franco and Jair Bolsonaro). For the US, Democratic and Republican parties were coded.].

## 3.3. Limitations

There are four main limitations with the theoretical and methodological approach of this article. First, the literature on authenticity and politics covers predominantly presidential democracies. Since the authenticity performances framework builds upon this literature, it is suitable to investigate and compare authenticity performances in in democratic contexts where electorates vote for politicians, instead of parties, as Brazil and the US. Moreover, since the authenticities in the framework are operationalized using a dictionary of terms constructed by listening to randomly selected samples of audio and textual data collected, the dictionary of terms is appropriate to capture authenticity performances in Brazil and the US. Adapting the framework to other presidential democracies would require updating to the the dictionary of terms that operationalizes authenticity performances.

Second, the operationalization of the framework does not grasp with the reception of authenticity performances (i.e. how authenticity performances are mediated or perceived by audiences). For this reason, randomly selected samples of authenticity performances matched in texts using the dictionary were selected to verify how they related to the theorized performances in the framework. The operationalization was found effective in matching the theorized authenticity performances, but other more ambiguous performances of authenticity were missed. That is, the operationalization dodges instances where interpretation is necessary and is cautious about what are, and not, authenticity performances in political discourses based on the framework. This means remaining on the side of caution when it comes to identifying and classifying authenticity performances.

Third, the framework and operationalization assume that authenticity performances identified are typically desirable and/or not hurtful. The framework conceptualizes authenticity as a performance, hence, politicians must put effort into constantly learning, adapting, and repeating performances to be deemed authentic. Even though diverse audiences might react differently to performances, by placing agency with both politicians and audiences the framework assumes that politicians learn, adapt, and repeat performances according to where, when, and to whom they speak.

Finally, the text data gathered misses social media settings where politics increasingly gets done (e.g. WhatsApp, Twitter, Facebook). This is a choice of consistency that prioritizes having a comparable dataset over time before social media was present or relevant in politics. With these limitations in mind, the findings in the subsequent analysis section are careful not to make causal claims about the relationship between the frequencies of authenticity performances and political outcomes. Despite of all these limitations, the authenticity performances framework offers an original pathway to systematically identify and compare authenticity in politics.

# 4 Analysis: How authenticity is performed in Brazil and the United States?

## 4.1 Authenticity Performances and Time

Even though appearing authentic to electorates influences election outcomes [@stiers2021; @valgarosson2021], there is no systematic increase in the total frequency of authenticity performances during election years in Brazil or the US over time. Figure 1, below, illustrates the total frequencies for authenticity performances in Brazil and the US over time. In the figure, the x-axis represents the years and the y-axis represents the sum of all normalized authenticity performances. The dots represent election years for each country. While there is no correlation between election years and authenticity performances in Brazil, election years correlate with a decrease in the total of authenticity performances in the US ^[The linear regression in Table 5 in Appendix shows that the relationship between election years and the total of authenticity performances in the US is negative and statistically significant.]. This suggests that some politicians (e.g. incumbents) in the US might generally be more careful towards when authenticity is performed close to elections as political discourses become more instrumental and less improvised. In Brazil, this suggests that authenticity is performed at comparable frequencies in election and non-election years on average.

```{r Figure 1, fig.cap="Authenticity Performances Over Time in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE}
aut_perf_time <- US %>%
 select(-c(doc_id, setting, settingc, text, char, speaker)) %>%
 group_by(year) %>%
 summarise(across(everything(), sum)) %>%
 mutate(truth_telling = (truth/length)*1000,
 lie_accusations = (lies/length)*1000,
 consistency = (consistency/length)*1000,
 finger_pointing = (fpoint/length)*1000,
 origins = (origins/length)*1000,
 common_sense = (common_sense/length)*1000,
 vulgarism = (anti_PC/length)*1000,
 territory = (territory/length)*1000) %>%
 select(-c(length, truth, lies, fpoint, anti_PC))
aut_perf_time_BR <- BR %>%
 select(-c(doc_id, setting, text, settingc, char, speaker)) %>%
 group_by(year) %>%
 summarise(across(everything(), sum)) %>%
 mutate(truth_telling = (truth/length)*1000,
 lie_accusations = (lies/length)*1000,
 consistency = (consistency/length)*1000,
 finger_pointing = (fpoint/length)*1000,
 origins = (origins/length)*1000,
 common_sense = (common_sense/length)*1000,
 vulgarism = (anti_PC/length)*1000,
 territory = (territory/length)*1000) %>%
 select(-c(length, truth, lies, fpoint, anti_PC))
# Plot over time
aut_perf_time_long <- aut_perf_time %>%
 tidyr::pivot_longer(consistency:vulgarism, names_to = "Performance")
aut_perf_time_long_BR <- aut_perf_time_BR %>%
 tidyr::pivot_longer(consistency:vulgarism, names_to = "Performance")
BR_ap_total <- aut_perf_time_long_BR %>% 
 select(-c(Performance)) %>%
 group_by(year) %>% 
 summarise(across(everything(), sum)) %>% 
 mutate(Country = "Brazil")
US_ap_total <- aut_perf_time_long %>% 
 select(-c(Performance)) %>%
 group_by(year) %>% 
 summarise(across(everything(), sum)) %>% 
 mutate(Country = "US")
ap_total_time <- dplyr::full_join(US_ap_total, BR_ap_total)
# Create labels for election years only
ap_total_time$ey <- ifelse(ap_total_time$Country == "US" &
  grepl("1988|1992|1996|2000|2004|2008|2012|2016|2020",
   ap_total_time$year),
  ap_total_time$year, "")
ap_total_time$ey <- ifelse(ap_total_time$Country == "Brazil" &
  grepl("1989|1994|1998|2002|2006|2010|2014|2018",
   ap_total_time$year),
  ap_total_time$year, ap_total_time$ey)
ap_total_time$ey <- ifelse(ap_total_time$ey != "", "EY", "")
#png("figure1.png", units="in", width=9, height=7, res=1000)
ggplot(ap_total_time, aes(x = as.Date(year, "%Y"),
  y = value, fill = Country)) +
 geom_line(aes(group = Country, color = Country)) +
 geom_point(data = filter(ap_total_time, ey != ""), size = 3.5, 
 aes(color = Country)) +
 scale_x_date(date_breaks = "4 years", date_labels = "%Y") +
 labs(x = "Year",
 y = "Normalized frequency (per 1000 words)",
 caption = "Dots mark election years in respective country.") +
 theme_clean(base_family = "Times", base_size = 12) +
 scale_color_manual(values = c("#F0E442", "#0072B2")) +
 theme(legend.position = "bottom", plot.background = element_blank())
#dev.off()
```

Brazil's party fragmentation and weak partisanship provide incentives for politicians to display individualistic behavior [@mainwaring1991; @mainwaring1999; @baker2020] that might include performing authenticity, in comparison to the US where politicians are more constrained by their parties. Authenticity has been performed with greater frequency in politics in Brazil in comparison to the US, particularly between 2011 and 2016 when Dilma Rousseff was president ^[The linear regression in Table 7 in Appendix shows that the relationship between the frequencies of authenticity performances and years when Rousseff was president is positive and statistically significant.]. Rousseff, arguably, performed authenticity more frequently to connect with audiences and justify her public policy choices than others in the sample to overcome the negative perceptions and gender stereotypes associated with her presidency [see @santos2021]. Women's distinct communication style in politics that includes disclosing more of personal details, using distinctive types of anecdotes, and justifying choices with concrete reasoning [@wood1994; @christine2005; @blankenship1995; @franceschet2016] might also affect how, when, and where they perform authenticity. However, the small number of women politicians in the data (i.e. Rousseff and Hillary Clinton) does not allow us to infer how gender and authenticity performances broadly correlate.
 
Allusions to origins and claims of truth-telling are the two most regularly performed authenticities by presidents and presidential candidates in Brazil and the US over time. Figure 2, below, illustrates the frequency of each authenticity performance over time in both cases. In the figure, the x-axis represents the years and the y-axis represents the normalized values of authenticity performances. The colored lines represent the different authenticity performances. Whereas origins is an authenticity performance about belonging and truth-telling is an authenticity performance about the self, both authenticities promote oneself instead of focusing on others. Unsurprisingly, politicians speak mostly about themselves when doing politics. Authenticity performances that focus on others, such as lie-accusations and finger-pointing, are performed infrequently on average in both countries ^[For more information see Table 6 in Appendix on the average proportion of authenticity performances in Brazil and the US.].

```{r Figure 2, fig.cap="Authenticity Performances by Category Over Time in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE}
aut_perf_type <- aut_perf_time %>%
 tidyr::pivot_longer(consistency:vulgarism) %>%
 mutate(category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
  "Belong", "Self")) %>%
 group_by(category, name, year) %>%
 summarise(value = sum(value)) %>%
 mutate(country = "United States")
aut_perf_type_BR <- aut_perf_time_BR %>%
 tidyr::pivot_longer(consistency:vulgarism) %>%
 mutate(category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
  "Belong", "Self")) %>%
 group_by(category, year, name) %>%
 summarise(value = sum(value)) %>%
 mutate(country = "Brazil")
ap_aut_perf_type <- rbind(aut_perf_type, aut_perf_type_BR) %>%
 mutate(ct = paste0(country, " - ", category))
#png("figure2.png", units="in", width=9, height=7, res=1000)
ggplot(ap_aut_perf_type, aes(x = as.Date(year, "%Y"), y = value)) + 
 geom_smooth(aes(color = name), alpha = 0.5, se = FALSE, linewidth = 0.7) +
 facet_wrap(facets = c("country", "category"),
            labeller = labeller(.multi_line = FALSE)) +
 scale_x_date(date_breaks = "4 years", date_labels = "%Y") +
 scale_color_brewer(palette = "Set2",
  labels = c("Common sense", "Consistency", "Finger poiting",
   "Lie accusations", "Origins", "Territory",
   "Truth telling", "Vulgarism")) +
 labs(x = "Year",
      y = "Normalized frequency (per 1000 words)",
      color = "",
 caption = "Averages lines are smoothed line using loess method") +
 theme_clean(base_family = "Times") +
 theme(legend.position = "bottom",
 plot.background = element_blank())
#dev.off()
```

Authenticity performances about the self and about belonging vary more over time in the Brazil than in the US. In Brazil, authenticity performances about belonging were performed with greater frequency, especially in the forms of origins and common sense, during the period in which the Workers Party (PT) were in office (2002-2016). This trend began to change in the mid-2010s and by 2019, the first year of the Bolsonaro administration, we see a reversal of this pattern where authenticity performances about the self, especially in the form of truth telling, surpass authenticity performances about belonging. The mid-2010s in Brazil were marked by recurrent corruption scandals in politics and an economic crisis. These factors arguably made authenticity performances associated with the PT governments less attractive to audiences and, in turn, politicians made efforts to favor other types of authenticity performances to distance themselves from PT in discourse. Conversely, in the US, the frequencies of authenticity performances about the self and about belonging remained relatively similar over time. Nevertheless, from the mid-2010s onwards there is a steady increase in authenticity performances about belonging, in the forms of origins and vulgarism, and a general decrease in performances about the self, in the forms of truth telling and consistency. The change in favor of authenticity performances that focus on shared cultural connections between politicians and audiences, arguably, reflects a response to American electorates that feel unrepresented by politicians they perceive to be disconnected with the opinions of ordinary citizens [see @boggild2020].

## 4.2 Authenticity Performances and Settings

In Brazil and the US debates have recently become the setting in which authenticity is performed most frequently whereas interviews are the setting in which authenticity is performed least. Figure 3, below, illustrates authenticity performances in Brazil and the US across setting over time. The x-axis represents the years and the y-axis represents the normalized values of authenticity performances. The colored lines represent different settings. In the US, authenticity performances occurred most frequently in campaign settings until the mid-2000s, but steadily decrease over time ^[The fixed-effects model in Table 10 in Appendix shows additional details about the correlations between authenticity performances, category, and setting in Brazil and the US.]. Conversely, in the case of Brazil, authenticity performances in campaigns, debates, and speeches generally increased until the mid-2010s. However, from the mid-2010s onwards we see a sharp decline in all authenticity performances. In both countries, debates recently become the setting in which authenticity is performed most frequently. As large-scale media events that requires candidates to answer quick to sometimes unpredictable questions, debates are an important sources of “sticky” sound and video bites charged with imagery that circulate in diverse media platforms to epitomize political cycles across democracies making it conducive to authenticity performances [@foley2012; @coleman2000]. Relatedly, interviews in both countries became the setting where authenticity is performed least frequently. The spread of social media gave politicians alternative outlets to interact directly with audiences, bypassing journalists and their filters in interviews, while performing authenticity directly to wider portions of the electorate [see @alexander2011, 106].

```{r Figure 3, fig.cap="Authenticity Performances by Setting Over Time in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE}
aut_perf_setting <- US %>%
 select(-c(doc_id, text, settingc, char, speaker)) %>%
 group_by(year, setting) %>%
 summarise(across(everything(), sum)) %>%
 mutate(truth_telling = (truth/length)*1000,
 lie_accusations = (lies/length)*1000,
 consistency = (consistency/length)*1000,
 finger_pointing = (fpoint/length)*1000,
 origins = (origins/length)*1000,
 common_sense = (common_sense/length)*1000,
 vulgarism = (anti_PC/length)*1000,
 territory = (territory/length)*1000) %>%
 select(-c(length, truth, lies, fpoint, anti_PC))
aut_perf_set_long <- aut_perf_setting %>%
 tidyr::pivot_longer(consistency:vulgarism) %>%
 mutate(category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
  "Belong", "Self")) %>%
 group_by(setting, year, category) %>%
 summarise(value = sum(value)) %>% 
 mutate(country = "United States")
aut_perf_setting_BR <- BR %>%
 select(-c(doc_id, text, settingc, char, speaker)) %>%
 group_by(year, setting) %>%
 summarise(across(everything(), sum)) %>%
 mutate(truth_telling = (truth/length)*1000,
 lie_accusations = (lies/length)*1000,
 consistency = (consistency/length)*1000,
 finger_pointing = (fpoint/length)*1000,
 origins = (origins/length)*1000,
 common_sense = (common_sense/length)*1000,
 vulgarism = (anti_PC/length)*1000,
 territory = (territory/length)*1000) %>%
 select(-c(length, truth, lies, fpoint, anti_PC))
aut_perf_set_long_BR <- aut_perf_setting_BR %>%
 tidyr::pivot_longer(consistency:vulgarism) %>%
 mutate(category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
  "Belong", "Self")) %>%
 group_by(setting, year, category) %>%
 summarise(value = sum(value)) %>% 
 mutate(country = "Brazil")
aut_perf_set_long_ap <- rbind(aut_perf_set_long, aut_perf_set_long_BR) %>% 
 mutate(Setting = factor(case_when(setting == 'interviews' ~ "Interviews",
   setting == 'debates' ~ "Debates",
   setting == 'speeches' ~ "Official Speeches",
   setting == 'campaign' ~ "Campaign Remarks"),
  levels = c("Official Speeches", "Campaign Remarks",
   "Debates", "Interviews")))
#png("figure3.png", units="in", width=9, height=7, res=1000)
ggplot(aut_perf_set_long_ap, aes(x = as.Date(year, "%Y"),
   y = value)) +
 geom_smooth(aes(color = Setting), se = FALSE, linewidth = 0.75) +
 scale_x_date(date_breaks = "4 years", date_labels = "%Y") +
 facet_wrap(facets = c("country"), nrow = 2) +
 scale_color_brewer(palette = "Set2", direction = 1) +
 labs(x = "Year",
 y = "Normalized frequency (per 1000 words)",
 caption = "Curves in the plot are smoothed using loess method.",
 color = "") +
 theme_clean(base_family = "Times") +
 theme(legend.position = "bottom",
 axis.text.x = element_text(angle = 90),
 plot.background = element_blank())
#dev.off()
```

Authenticity is performed in more diverse ways across different settings in Brazil than in the US. Figure 4, below, illustrates the averages for authenticity performances about the self and about belonging in Brazil and the US across settings. The x-axis represents the mean normalized averages and the y-axis represents the settings. The colored columns represent the category of authenticity performances. In the US, authenticity performances about belonging appear more frequently on average across all settings, especially in campaigns. In Brazil, authenticity performances about belonging appear more frequently on average in official speeches and interviews, while authenticity performances about the self-appear more frequently on average in debates and campaigns. Politicians in the US are, arguably, more consistent in the authenticities they perform independent of the setting they speak at in comparison to Brazil where setting affects which authenticities are performed.

```{r Figure 4, fig.cap="Authenticity Performances by Category across Settings in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE}
aut_perf_setting_BR_table <- aut_perf_setting_BR %>% 
 tidyr::pivot_longer(consistency:vulgarism) %>%
 mutate(country = "Brazil",
 category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
  "Belong", "Self")) %>% 
 group_by(setting, category, country) %>%
 summarise(value = mean(value))
aut_perf_setting_US_table <- aut_perf_setting %>% 
 tidyr::pivot_longer(consistency:vulgarism) %>%
 mutate(country = "US",
 category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
  "Belong", "Self")) %>% 
 group_by(setting, category, country) %>%
 summarise(value = mean(value))
aut_perf_setting_table <- rbind(aut_perf_setting_BR_table, 
   aut_perf_setting_US_table)
#png("figure4.png", units="in", width=9, height=7, res=1000)
ggplot(aut_perf_setting_table, aes(y = setting,
   x = value)) +
 geom_col(aes(fill = category), position = "dodge") +
 facet_wrap("country", nrow = 2) +
 scale_fill_discrete(labels = c("Belong", "Self")) +
 scale_y_discrete(labels = c("Campaign Remarks", "Debates",
  "Interviews", "Official Speeches")) +
 scale_fill_brewer(palette = "Dark2", direction = 1) +
 labs(y = "",
 x = "Mean normalized frequency (per 1000 words)",
 fill = "") +
 theme_clean(base_family = "Times") +
 theme(legend.position = "bottom",
 plot.background = element_blank())
#dev.off()
```

## 4.3 Authenticity Performances and Politicians' Roles

Presidential candidates perform authenticity more frequently than elected presidents in the US while, in Brazil, authenticity is performed at comparable rates independent of a politicians' role. Figure 5, below, illustrates the relationship between politicians' roles and the normalized total for authenticity performances or the diversity scores for authenticity performances. The x-axis represents the estimated coefficients by the fixed-effects models and the y-axis represents the independent variable, politicians' roles, and the control variable, political party. The lines in the figure represent the standard errors generated by each of the models. In practice, lines that do not touch doted vertical line symbolize a statistically significant relationship ^[For more information see the full model in Table 8 in Appendix. As well, please refer to Table 9 in Appendix for the same model controlling for setting and category of performances. Since the findings were relatively similar and unsurprisingly, the simpler model was preferred.]. The models about the total frequencies of authenticity performances (US Total and BR Total) suggest that politicians in the US perform authenticity less frequently when in office in comparison to candidates, the reference category. Candidates in the US are likely running for a first time for president and must perform authenticity to attract national attention and secure party nominations. Once in office, presidents perform authenticity significantly less. This also helps explain why there is a negative relationship between authenticity performances and election years in the US (section 4.1 above), incumbents running for office perform authenticity less often. In Brazil, even though authenticity performances happen at a higher frequency and are more diverse across settings (sections 4.1. and 4.2 above), authenticity performances take place at comparable frequencies regardless of politicians' roles.

```{r figure 5, fig.cap="Fixed-Effects Models for Authenticity Performances by Politicians' Roles", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
US_mod <- US %>%
 select(-c(doc_id, text, settingc, char)) %>% 
 group_by(year, speaker, setting) %>%
 summarise(across(everything(), sum)) %>%
 mutate(truth_telling = (truth/length)*1000,
 lie_accusations = (lies/length)*1000,
 consistency = (consistency/length)*1000,
 finger_pointing = (fpoint/length)*1000,
 origins = (origins/length)*1000,
 common_sense = (common_sense/length)*1000,
 vulgarism = (anti_PC/length)*1000,
 territory = (territory/length)*1000,
 total = truth_telling + lie_accusations + consistency + 
 finger_pointing + origins + common_sense + vulgarism + territory,
 diversity = abdiv::dominance(c(truth_telling, lie_accusations, consistency,
 finger_pointing, origins, common_sense, vulgarism, territory)),
 status = factor(case_when(speaker == "Bush" & year > 1988 & year < 1993 |
  speaker == "Clinton" & year > 1992 & year < 2001 |
  speaker == "W.Bush" & year > 2000 & year < 2009 |
  speaker == "Obama" & year > 2008 & year < 2017 |
  speaker == "Trump" & year > 2016 & year < 2021 |
  speaker == "Biden" & year > 2020 ~
  "In Office",
  speaker == "Bush" & year > 1992 |
  speaker == "Clinton" & year > 2000 |
  speaker == "W.Bush" & year > 2008 |
  speaker == "Obama" & year > 2016 |
  speaker == "Trump" & year > 2020 ~
  "After office",
 .default = "Candidates"),
  levels = c("Candidates",
   "In Office",
   "After office")),
 party = factor(case_when(speaker == "Bush" | speaker == "Dole" | 
   speaker == "W.Bush" | speaker == "McCain" | 
   speaker == "Romney" | 
   speaker == "Trump" ~ "Republican",
  .default = "Democratic"),
  levels = c("Republican", "Democratic"))) %>%
 select(-c(length, truth, lies, fpoint, anti_PC, truth_telling, lie_accusations,
 consistency, finger_pointing, origins, common_sense, vulgarism, territory)) %>%
 dplyr::distinct()
BR_mod <- BR %>%
 select(-c(doc_id, text, settingc, char)) %>% 
 group_by(year, speaker, setting) %>%
 summarise(across(everything(), sum)) %>%
 mutate(truth_telling = (truth/length)*1000,
 lie_accusations = (lies/length)*1000,
 consistency = (consistency/length)*1000,
 finger_pointing = (fpoint/length)*1000,
 origins = (origins/length)*1000,
 common_sense = (common_sense/length)*1000,
 vulgarism = (anti_PC/length)*1000,
 territory = (territory/length)*1000,
 total = truth_telling + lie_accusations + consistency + 
 finger_pointing + origins + common_sense + vulgarism + territory,
 diversity = abdiv::dominance(c(truth_telling, lie_accusations, consistency,
 finger_pointing, origins, common_sense, vulgarism, territory)),
 status = factor(case_when(speaker == "Lula" & year > 2002 & year < 2011 |
  speaker == "Collor" & year > 1989 & year < 1993 |
  speaker == "Franco" & year > 1992 & year < 1995 |
  speaker == "Cardoso" & year > 1994 & year < 2003 |
  speaker == "Rousseff" & year > 2010 & year < 2017 |
  speaker == "Temer" & year > 2016 & year < 2019 |
  speaker == "Bolsonaro" & year > 2018 ~
  "In Office",
  speaker == "Lula" & year > 2010 |
  speaker == "Collor" & year > 1992 |
  speaker == "Franco" & year > 1994 |
  speaker == "Cardoso" & year > 2002 |
  speaker == "Rousseff" & year > 2016 |
  speaker == "Temer" & year > 2018 ~ 
  "After office",
 .default = "Candidates"),
  levels = c("Candidates",
   "In Office",
   "After office")),
 party = factor(case_when(speaker == "Cardoso" | speaker == "Alckmin" | 
   speaker == "Serra" | speaker == "Neves" ~ "PSDB",
   speaker == "Bolsonaro" | speaker == "Collor" | 
   speaker == "Franco" | speaker == "Temer" ~ "Other",.default = "PT"),
  levels = c("PT", "PSDB", "Other"))) %>%
 select(-c(length, truth, lies, fpoint, anti_PC, truth_telling, lie_accusations,
 consistency, finger_pointing, origins, common_sense, vulgarism, territory)) %>%
 dplyr::distinct()
US_model_total <- plm(total ~ status + party,
  data = US_mod, model = "within", index = c("year"))
BR_model_total <- plm(total ~ status + party,
  data = BR_mod, model = "within", index = c("year"))
US_model_div <- plm(diversity ~ status + party,
  data = US_mod, model = "within", index = c("year"))
BR_model_div <- plm(diversity ~ status + party,
  data = BR_mod, model = "within", index = c("year"))
#png("figure5.png", units="in", width=9, height=7, res=1000)
jtools::plot_summs(US_model_total, BR_model_total,
  US_model_div, BR_model_div,
  model.names = c("US Total","BR Total",
   "US Diversity", "BR Diversity"),
  legend.title = "Models") +
 labs(caption = "Fixed-Effects models indexed by year",
 y = "") +
 scale_y_discrete(labels = c("Other Parties", "PSDB", "Democrat", "After office", "In Office")) +
 theme_clean(base_family = "Times") +
 theme(legend.position = "bottom",
 plot.background = element_blank())
#dev.off()
```

Presidents are less diverse in the ways in which they perform authenticity when in office. The models about the diversity of authenticity performances (US Diversity and BR Diversity) illustrate the relationship between performing multiple authenticity performances at similar rates and politicians' roles. In both Brazil and the US, presidential candidates tend to perform multiple authenticities rather than concentrate performances around a single authenticity. Presidents likely learn from what types of performance “stick” when campaigning and, once in office, adapt to perform authenticities that work for them.

# 5 Conclusion

This article develops an original framework to identify and compare how authenticity is performed in political discourses over time, across settings, and by politicians. To demonstrate the usefulness of the framework, this article investigates authenticity performances in 21,496 political texts of electoral debates, interviews, campaigns, and official speeches for presidents and presidential candidates in Brazil and the US since 1988. The findings indicate that authenticity is not performed more frequently in election years. Authenticity is generally performed with greater frequency in Brazil than in the US. Brazil's party fragmentation and weak partisanship provide incentives for politicians to display individualistic behavior that might include performing authenticity more often and in more diverse forms across settings, in comparison to the US where politicians are typically more constrained by their parties. In both countries debates have recently become the setting in which authenticity is performed most frequently, whereas interviews are the setting in which authenticity is performed least frequently. Debates are large scale media events that produce “sticky” sound and visual bites charged with imagery that circulate more than ever in democracies. Relatedly, social media platforms give politicians diverse outlets to interact directly with audiences, bypassing journalists in interviews. In the US, presidential candidates perform authenticity more frequently than elected presidents while, in Brazil, authenticity is performed at comparable rates independent of a politicians' role. In both cases, presidential candidates' tend to perform multiple types of authenticities but, once elected, presidents likely learn from what types of performance “stick” and adapt to perform only the authenticities that work for them.

This article lays down the foundations for comparative research on authenticity in politics. Conceptually, this article provides the first framework for identifying and comparing diverse authenticity performances in politics. Empirically, besides the datasets of political texts for presidents and presidential candidates, this article provides the first comparative overview of how, where, and when authenticity has been performed in politics in in Brazil and the US since 1988. Future research should move beyond the frequency and forms in which authenticities are performed, to consider how, when, and where each of these authenticity performances help to build electoral trust from electorates [see @weinberg2023]. Likewise, future research should investigate authenticity performances in different types of political systems, such as electoral autocracies. This could be especially pertinent to understand how certain autocratic politicians discursively collect support from large portions of populations even when they might not be democratically accountable to them. Additionally, since authenticity is one of many forms of collecting and maintaining support when “doing politics”, future research should investigate how authenticity performances interact, affect, and change electorates perception of public policies. Lastly, it is important to expand on the ways in which different social media platforms mediate gendered and ethno-racial performances of authenticity to broad audiences [see @welp2017]. Given the importance authenticity perceptions have for political outcomes, understanding the role of authenticity in politics could be essential to grasp with why elected politicians frequently do not appear representative of their own electorates.
 
It is an enormous challenge for political scientists to understand when, why, and how political discourses matter for political outcomes in democracies. We have long known, for example, that the diffusion of mass media has not made electorates better informed about politics or about politicians' governing programs [@denton1988]. Still, political scientists continuously engage with the meaning related to what politicians say to explain electoral outcomes. A misplaced engagement with the logic of why electorates and politicians behave as they do contribute to furthering political polarization by passing on the blame for “undesirable” political outcomes to a lumped together group of “old, rural, or uneducated” electorates. This is especially true for a significant portion of the populism literature that focus on materialist explanations (i.e. economically left behind) for electoral behavior [see @schafer2022], while frequently disregarding other important aspects of “doing politics” as authenticity. Authenticity performances, as a framework, offers an alternative to understand what certain political discourses are, how they change over time, and why they might matter for political outcomes.

# References

<div id="refs"></div>

# Appendix

````{=tex}
```{r table ec, fig.cap="Text data by election and politicians cycle in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
# For more info on observations, please refer to "total_obs.R" file in the data folder.
US_t_table <- readRDS("~/Documents/GitHub/authenticity_performances/article/Resubmission/US_t_table.Rds")
BR_t_table <- readRDS("~/Documents/GitHub/authenticity_performances/article/Resubmission/BR_t_table.Rds")
ttable <- rbind(US_t_table, BR_t_table) %>%
  rename('Election Cycle' = election_cycle, Politicians = politicians,
         Setting = setting, Observations = obs)
kbl(ttable, booktabs = T,
 caption = "Text data by election and politicians cycle in Brazil and the US") %>%
 kable_styling(latex_options = "HOLD_position")
```
````

````{=tex}
\begin{landscape}
```{r codebook, fig.cap="Authenticity Performances Codebook", echo=FALSE, message=FALSE, warning=FALSE, include=TRUE}
codebook <- tibble::tibble("Authenticity Performance" = c('Truth Telling', 'Lie accusations', 'Consistency' , 'Finger Pointing', 'Origins', 'Common Sense', 'Vulgarism', 'Territory'),
"Lexicon English" = c("am telling the truth, are telling the truth, is telling the truth, the truth is, this is the truth, not lying, not lies, no lies, not telling you lies, is honest, am honest, is being honest, are being honest, are honest, honesty, is sincere, are sincere, am sincere, is being sincere, are being sincere, is true, are true, not a liar, bottom of my heart, I swear, I reassure, we reassure, I assure, we assure, be assured, is truthful, are truthful, am truthful, is being truthful, are being truthful, I know that, is evident, are evident, I am sure, trust me, am frank, are frank, is frank, being frank, is upfront, are upfront, am upfront, being upfront, will come clean, am coming clean, are coming clean, is straightforward, are straightforward, being straightforward, believe me, I am certain, no bullshit, not bullshitting",
"not truth, not the truth, not true, aren't true, isn't true, being untruthful, is lying, are lying, is a liar, are liars, is dishonest, are dishonest, being dishonest, is fake, are fake, being fake, is corrupt, are corrupt, full of lies, not sincere, not being sincere, isn't sincere, aren't sincere, not honest, not being honest, is cheating, is a cheater, are cheaters, are cheating, are tricking, is tricking, be deceived, is deceiving, are deceiving, are a hypocrite, is a hypocrite, are being a hypocrite, is being a hypocrite, is crooked, are crooked, is misleading, are misleading, has double-standards, are sneaky, is sneaky, has two faces, two-faced, has double faces, double-faced, you are wrong, not correct, fooled by, do not believe, is misrepresenting, they misrepresent, is misrepresent, are misrepresent, pretends that, pretends to, is pretending, are pretending, keep pretending, breach your trust, breach of trust, is false, are false, being false, is misinforming, are misinforming, being misinformed, pretended, cut the crap, full of crap",
"we delivered, I delivered, check and see, I keep my word, we keep our word, I kept my word, we kept our word, I keep my promise, I kept my promise, we keep our promise, as promised, we kept our promise, am responsible, I take responsibility, we take responsibility, we assume responsibility, we are accountable, we are responsible, our duty, my duty, give my word, giving my word, own up my, owning up my, accept responsibility, accept the blame, recognize my mistakes, admit I was wrong, I made mistakes, I guarantee, we guarantee, I can guarantee, we can guarantee, I promise, we promise, we can prove, I can prove, we proved, I proved, am reliable, rely on me, rely on us, be reassured, you can hold me accountable, you can hold us accountable, see with your own eyes, vote of confidence, our mission, my mission, my commitment, our commitment, during our government, during my government, while I was in charge",
"are inconsistent, is inconsistent, being inconsistent, are irresponsible, is irresponsible, being irresponsible, their fault, not my fault, not our fault, they left us with, they are responsible, are not responsible, aren't responsible, is not responsible, isn't responsible, costed us, false promises, lack accountability, lacking accountability, not kept their word, not kept his word, not kept her word, not kept promises, not kept the, not kept his, not kept her, not kept their, not keep their word, not keep his word, not keep her word, not keep the, didn't keep the, didn't keep her, didn't keep his, hasn't kept his, hasn't kept her, not recognize, he made mistakes, she made mistakes, they made mistakes, not our mistake, not my mistake, not take responsibility, not my responsibility, not accountable, him accountable, them accountable, her accountable, blame them, blame him, blame his, blame her, their blame, break promises, broken promises, has betrayed, they betrayed, betraying, will betray, has tricked, has lied, not deliver, didn't deliver, hasn't deliver, failed your obligations, failed in your obligations, failed his obligations, failed her obligations, failed in his duty, failed in her duty, failed his duty, failed her duty, failed your duties, stabbed in the back",
"I was born, I come from, we come from, I grew up, growing up in, my parents, my mom, my mother, my father, my dad, my family, raised me, I was raised, we were raised, we grew up, my background, being surrounded by, being exposed to, my siblings, going to school in, our local church, Sunday mass, Saturday mass, family tradition, tradition in my house, in our house, growing up, back in the day, my grandparents, in my town, in my state, in my region, our community, in my community, our town, our state, my hometown, our hometown, my home state, our home state, back home, our house, my house, our neighbourhood, in my district, I lived in, we lived in, we used to play, I used to play, I was thought",
"is common sense, are common sense, everyone knows, it is undeniable, stating the obvious, say the obvious, everyone agrees, we all know, common wisdom, the people know, popular knowledge, from experience, it is my experience, sound judgment, practical solution, practical choice, practical answer, pragmatic solution, pragmatic answer, pragmatic choice, realistic answer, let me tell you about, is obvious, are obvious, obvious answer, obvious solution, as we all learned, we have all learned that, do not need to tell you that, the reality is, there is no logic, it does not make sense, it doesn't make sense, we know it does not work, no one disagrees that, no person disagrees, there is not a person, there is not a human being, there is not a family, there is not an American, there is no single citizen, there is not one single person, there is not one single human being, there is not one single family, there is not one single American, there is not one single citizen, there is not one single person, there is not one human being, there is not one family, there is not one American",
"politically correct, political correctness, PC, plain speaking, speaking my mind, speak my mind, say what I think, saying what I think, not going to pretend, not pretend, speak what you think, not what you want to hear, not butter up, not beat around the bush, cut to the chase, just being real, saying what everyone thinks, say what everyone is thinking, speaking plainly, colored people, negro, retarded, nigger, third world, oriental people, crippled people, is crippled, culturally deprived, drug addict, junkie, drunk, fat people, fat person, fat population, handicapped, homosexual faggot, deviant, perverted, illegals, illegal immigrants, illegal alien, Jew, non-white, prostitutes, promiscuous, stupid, tribe, underdeveloped",
"have been to, have visited, came all the way to, back from, will visit, saw first-hand, see first-hand, we visited, I visited, we visited, traveled to, traveling to, spend a few days in, spent some time in, spent time in, met great people in, we were hosted, I was hosted, our time in, my time in, our visit, spent a lot of time in, were many times in, got to know the whole country, got to know all the states"),
"Lexicon Portuguese" = c("a verdade e, esta e a verdade, digo a verdade, dizemos a verdade, pura verdade, nao e mentira, nao estou mentindo, e honesto, sou honesto, somos honesto, sendo honesto, a honestidade, ser sincero, e sincero, com sinceridade, e verdade, sao verdadeiras, nao sou mentiroso, nao minto, fundo do meu coracao, sou verdadeiro, somos verdadeiros, tenho certeza, certeza absoluta, confia em mim, confie em mim, pode confiar, sou franco, somos francos, fraqueza, falando a verdade, falo a verdade, falamos a verdade, acredite em mim, pode acreditar, podem acreditar, eu tenho certeza, isso e a verdade, somos honestos, com honestidade, toda a sinceridade, com sinceridade, toda sinceridade, sou confiavel, somos confiaveis, as coisas sao assim, a realidade das coisas, juro por deus, com certeza, digo com precisao, veracidade, premissa, afirmo para voces, isso e como aconteceu, falar umas verdades",
"nao e verdade, nao e verdadeiro, e mentiroso, esta mentindo, sao mentiroso, e mentira, de mentira, tudo mentira, e desonesto, mentiram, mentiu, um desonesto, esse desonesto, de desonesto, sao desonesto, e falso, sao falsos, sao corruptos, e corrupto, de corrupto, todos corrupto, nao sao sincero, nao e sincero, nao sao honestos, nao e honesto, sao trapaceiros, e trapaceiro, eles trapaceiam, trapaceou, e enganar, ser enganado, vao enganar, sendo enganados, e hipocrita, e enganador, e enganacao, duas caras, enganado por, nao acredite, eles finge, ele finge, e fingimento, ela finge, quebrou a sua confianca , quebra de confianca, e falso, sao falsos, falsidade, e ficcao, historia para boi dormir, historinha para boi dormir, e calunia, sao calunias, difamacao, difamar, uma inverdade, sao inverdades, e inverdade, isso e invencao, essas sao invencoes, isso e uma lenda, essas sao ledas, tenta iludir, tentando iludir, uma farsa, tramoia, mal intencionado, mas intencoes, falta de informacao, esta mal-informado, estao mal-informados",
"nos entregamos, eu entreguei, veja com seus proprios olhos, cumpro minhas palavras, cumprimos nossas palavra, cumpri minha palavra, cumpro minhas promessas, nossas promessa, um compromisso, meu compromisso, tenho um compromisso com, eu sou responsavel, eu assumo a responsabilidade, nos somos responsaveis, nos assumimos a responsabilidade, nosso dever, meu dever, dou minha palavra, faco uma promessa, fazer uma promessa, aceitar a responsabilidade, aceito a responsabilidade, aceitamos a responsabilidade, aceitar a culpa, meus erros, que errei, eu errei, eu garanto, eu posso garantir, eu prometo, podemos provar, posso provar, provaremos, eu provei, voto de confianca, encarrego pessoalmente, encarreguei pessoalmente, estou comprometido, meu comprometimento, comprometimento com, o comprometimento, fazer o possivel, minha supervisao, minha missao, nossa missao, no meu governo, no nosso governo, durante nosso governo, eu era encarregado, eu era o encarregado, fomos encarregados de",
"e inconsistente, sao inconsistente, e irresponsavel, sao irresponsaveis, culpa deles, a culpa nao e minha, nao e minha culpa, eles nos deixaram, sao responsaveis, e responsavel, nos custou, falsas promessas, falta de prestacao de contas, falharam, falhou, nao cumpriu, nao cumpriram, nao reconheceu, nao reconheceram, errou, erraram, nao se responsabiliza, nao me responsabilizo, culpa e sua, sua culpa, quebrar promessas, promessas quebradas, quebra de promessas, fala uma coisa e faz outra, fala uma coisa aqui e faz outra, falsas promessas, sao trapaceiros, cometeu erros, cometeram erros, nao reconhece, nao reconheceu, assumiu a responsabilidade, promete uma coisa, promete o mundo, traiu a confianca, traiu a sua confianca, quebra de confianca, quebraram sua confianca, e falcatrua, foi falcatrua, cheio de falcatrua, houve fraude, houveram fraudes, fraudulento, uma negociata, facada nas costas, faltou com respeito, nao faz o que promete, nao fez o que promete, promessas em vao, palavras em vao, falta de comprometimento, falta de compromisso, houveram desvio, houve desvio, a culpa e do, cheio de promessas, a conta nao fecha, nao terminaram",
"Eu nasci, Eu vim de, eu venho de, viemos de, cresci, nos crescemos, meus pais, minha mae, minha mae, minha familia, fui criado, fomos criados, minhas origens, meus irmaos, meu irmao, minha irma, tradicao familiar, tradicao em casa, crescendo, antigamente, meu avo, minha avo, meus avos, na minha cidade, no meu estado, na minha regiao, nossa comunidade, na minha comunidade, nossa cidade, nosso estado, cidade natal, estado de origem, minha casa, nossa casa, la em casa, nosso bairro, no meu bairro, eu morava, viviamos, na minha terra, de onde eu venho, missa de domingo, missa toda semana, brincava, eram outros tempos, fui educado, moravamos, eu morei, nos moramos, de onde venho, eram tempos diferentes",
"senso comum, bom senso, todos sabem, afirmando o obvio, todos concordam, todos sabemos, sabemos todos, todos nos sabemos, sabedoria popular, por experiencia, e minha experiencia, sou pratico, tem que ser pratico, devemos ser pratico, sendo pratico, sou pragmatico, tem que ser pragmatico, devemos ser pragmatico, sendo pragmatico, sou realista, sendo realista, sejamos realista, realisticamente falando, e obvio, como todos nos aprendemos, como sabemos, nao preciso te dizer, o povo sabe, agente aprendeu, nos aprendemos, nos sabemos, nao tem logica, como aprendemos, nao faz sentido, nao fazem sentido, estamos cansados de saber, sabemos que nao funciona, ninguem discorda que, nao tem uma pessoa, nao existe uma pessoa, nao ha uma pessoa, nao existe um ser humano, nao tem um ser humano, nao ha um ser humano, nao tem uma familia, nao existe uma familia, nao ha uma familia, nao tem um brasileiro, nao ha um Brasileiro, nao existe um brasileiro, nao tem uma brasileira, nao ha uma Brasileira, nao existe uma brasileira",
"politicamente correto, falar francamente, falando francamente, falar o que penso, falo o que penso, falando o que penso, dizer o que penso, papas na lingua, nao vou fingir, nao estou aqui para agradar, falar o que voce pensa, o que voce quer ouvir, nao adulterar, nao rodeio, nao dou rodeio, direto ao ponto, dizer o que todos pensam, dizendo o que penso, dizendo o que todos pensam, dizer o que todos estao pensando, nao vou amaciar, nao da para amaciar, gordos, retardado, retardada, veado, populacao preta, os pretos, as pretas, terceiro mundo, viciado em drogas, bebado, drogado, sem cultura, pervertidos, promiscuo, imbecil, estupido, aleijado, defeituoso, incapacitado, invalido, mongoloide, deficiente mental, deficiencia mental, o incapacitado, a incapacitada, travesti, homossexualismo",
"estive em, visitei, voltou de, voltei de, voltando de, voltamos de, estive em, estivemos em, visitara, visitarei, vi em primeira mao, ver em primeira mao, visitamos, viajei para, passei alguns dias em, passei algum tempo em, passei um tempo, conheci otimas pessoas, conhecemos otimas pessoas em, fomos hospedados, minha passagem, nossa passagem, nossa visita, fui muitas vezes para, estive muitas vezes em, passei muito tempo em, meu tempo em, estive por todo o Brasil, de norte a sul do pais, conheco todo o pais, conheci todo o pais, conheci todo o Brasil, conheco todo o Brasil"))

codebook$`Lexicon Portuguese` <- as.character(codebook$`Lexicon Portuguese`)
codebook$`Lexicon Portuguese` <- stringi::stri_trans_general(codebook$`Lexicon Portuguese`, id = 'latin-ascii')

kbl(codebook, booktabs = T, longtable = TRUE,
 caption = "Authenticity Performances Codebook") %>%
 kable_styling(latex_options = c("hold_position", "repeat_header"),
 font_size = 7, full_width = TRUE) %>%
 column_spec(1, width="2cm", bold=TRUE) %>%
 column_spec(2, width="6cm") %>%
 column_spec(3, width = "8cm")
```
\end{landscape}
````

\newpage

````{=tex}
```{r table 5, fig.cap="Authenticity Performances and Election Years in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
check_ey <- lm(value ~ as.factor(ifelse(ey == "EY", 1, 0)) + as.factor(Country), ap_total_time)
stargazer::stargazer(check_ey,
  title = "Authenticity Performances and Election Years in Brazil and the US",
  covariate.labels = c("Election Year", "United States"))
```
````

\newpage

````{=tex}
```{r table 6, fig.cap="Authenticity Performances by Year in Brazil", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
ap_total_time_br <- ap_total_time %>% 
 dplyr::filter(Country == "Brazil") %>%
 mutate(cycle = case_when(year < 1995 ~ "Collor/Franco (1989-1994)",
  year > 1994 & year < 2003 ~ "Cardoso (1995-2002)",
  year > 2002 & year < 2011 ~ "Lula (2003-2010)",
  year > 2010 & year < 2019 ~ "Rousseff/Temer (2011-2018)",
  year > 2018 ~ "Bolsonaro (2019 to 2022)"))
check_year_br <- lm(value ~ cycle, ap_total_time_br)
stargazer(check_year_br,
 title = "Authenticity Performances by year in Brazil - Linear Model")
```
````

\newpage

````{=tex}
```{r table 7, fig.cap="Average Normalized Proportion of Authenticity Performances in Brazil and the US (per 1000 words)", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
BR_mean <- apply(aut_perf_time_BR, 2, function(x) mean(as.numeric(x)))
US_mean <- apply(aut_perf_time, 2, function(x) mean(as.numeric(x)))
table7 <- tibble::tibble("Authenticity Performance" = c("Truth Telling", 
    "Lie Accusations",
    "Consistency ",
    "Finger Pointing", 
    "Origins",
    "Common Sense", 
    "Territorial",
    "Anti-PC"),
  "Average US" = c("0.33", "0.04",
   "0.19", "0.02", 
   "0.34", "0.06",
   "0.10", "0.09"),
  "Average Brazil" = c("0.35", "0.03",
   "0.20", "0.06", 
   "0.85", "0.25",
   "0.05", "0.03"))
kbl(table7, booktabs = T,
 caption = "Average Normalized Proportion of Authenticity Performances in Brazil and the US (per 1000 words)") %>%
 kable_styling(latex_options = "HOLD_position") %>%
 column_spec(1, bold=TRUE)
```
````

\newpage

````{=tex}
```{r table 8, fig.cap="Authenticity Performances by Setting in Brazil and the US", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
tsetting_US <- plm(value ~ Setting*category,
  data = filter(aut_perf_set_long_ap,
   country == "United States"),
  model = "within", index = "year")
tsetting_BR <- plm(value ~ Setting*category,
  data = filter(aut_perf_set_long_ap,
   country == "Brazil"),
  model = "within", index = "year")
stargazer(tsetting_BR, tsetting_US,
 title = "Authenticity Performances by Category and Setting in Brazil and the US - Fixed-Effects by Year",
 column.labels = c("Brazil", "US"),
 dep.var.labels = "Total Frequency")
```
````

\newpage

````{=tex}
\begin{landscape}
```{r table 9, fig.cap="Authenticity Performances by Politicians' Role in Brazil and the US - Fixed-Effects by year", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
stargazer(US_model_total, BR_model_total, US_model_div, BR_model_div,
 title = "Authenticity Performances by Setting, Category, Status, 
 and Party in Brazil and the US - Fixed-Effects by Year",
 column.labels = c("US", "Brazil", "US", "Brazil"),
 dep.var.labels = c("Total Normalized Frequency", "Diversity Score"))
```
\end{landscape}
````

````{=tex}
\begin{landscape}
```{r table 10, fig.cap="Authenticity Performances by Politician's Role in Brazil and the US - Fixed-Effects by year controling for setting and category", echo=FALSE, message=FALSE, warning=FALSE, paged.print=TRUE, include=TRUE, results="asis"}
US_mod <- US %>%
select(-c(doc_id, text, settingc, char)) %>%
group_by(year, speaker, setting) %>%
summarise(across(everything(), sum)) %>%
mutate(truth_telling = (truth/length)*1000,
lie_accusations = (lies/length)*1000,
consistency = (consistency/length)*1000,
finger_pointing = (fpoint/length)*1000,
origins = (origins/length)*1000,
common_sense = (common_sense/length)*1000,
vulgarism = (anti_PC/length)*1000,
territory = (territory/length)*1000,
diversity = abdiv::dominance(c(truth_telling, lie_accusations, consistency,
finger_pointing, origins, common_sense, vulgarism, territory)),
status = factor(case_when(speaker == "Bush" & year > 1988 & year < 1993 |
  speaker == "Clinton" & year > 1992 & year < 2001 |
  speaker == "W.Bush" & year > 2000 & year < 2009 |
  speaker == "Obama" & year > 2008 & year < 2017 |
  speaker == "Trump" & year > 2016 & year < 2021 |
  speaker == "Biden" & year > 2020 ~
  "In office",
 speaker == "Bush" & year > 1992 |
  speaker == "Clinton" & year > 2000 |
  speaker == "W.Bush" & year > 2008 |
  speaker == "Obama" & year > 2016 |
  speaker == "Trump" & year > 2020 ~
  "After office",
.default = "Candidate"),
 levels = c("Candidate", "In office", "After office")),
party = factor(case_when(speaker == "Bush" | speaker == "Dole" |
  speaker == "W.Bush" | speaker == "McCain" |
  speaker == "Romney" |
  speaker == "Trump" ~ "Republican",
 .default = "Democratic"),
 levels = c("Republican", "Democratic")),
setting = factor(setting, levels = c("campaign", "speeches", "debates", "interviews"))) %>%
select(-c(length, truth, lies, fpoint, anti_PC)) %>%
pivot_longer(consistency:vulgarism) %>%
mutate(category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
 "Belong", "Self")) %>%
group_by(year, speaker, setting, diversity, status, party, category) %>%
summarise(total = sum(value)) %>%
dplyr::distinct()
BR_mod <- BR %>%
select(-c(doc_id, text, settingc, char)) %>%
group_by(year, speaker, setting) %>%
summarise(across(everything(), sum)) %>%
mutate(truth_telling = (truth/length)*1000,
lie_accusations = (lies/length)*1000,
consistency = (consistency/length)*1000,
finger_pointing = (fpoint/length)*1000,
origins = (origins/length)*1000,
common_sense = (common_sense/length)*1000,
vulgarism = (anti_PC/length)*1000,
territory = (territory/length)*1000,
diversity = abdiv::dominance(c(truth_telling, lie_accusations, consistency,
finger_pointing, origins, common_sense, vulgarism, territory)),
status = factor(case_when(speaker == "Lula" & year > 2002 & year < 2011 |
  speaker == "Lula" & year > 2020 |
  speaker == "Collor" & year > 1989 & year < 1993 |
  speaker == "Franco" & year > 1992 & year < 1995 |
  speaker == "Cardoso" & year > 1994 & year < 2003 |
  speaker == "Rousseff" & year > 2010 & year < 2017 |
  speaker == "Temer" & year > 2016 & year < 2019 |
  speaker == "Bolsonaro" & year > 2018 ~
  "In office",
 speaker == "Lula" & year > 2010 & year < 2020 |
  speaker == "Collor" & year > 1992 |
  speaker == "Franco" & year > 1994 |
  speaker == "Cardoso" & year > 2002 |
  speaker == "Rousseff" & year > 2016 |
  speaker == "Temer" & year > 2018 ~
  "After office",
.default = "Candidate"),
 levels = c("Candidate", "In office", "After office")),
party = factor(case_when(speaker == "Cardoso" | speaker == "Alckmin" |
  speaker == "Serra" | speaker == "Neves" ~ "PSDB",
  speaker == "Bolsonaro" | speaker == "Collor" |
  speaker == "Franco" | speaker == "Temer" ~ "Other",.default = "PT"),
 levels = c("PT", "PSDB", "PMDB", "Other")),
setting = factor(setting, levels = c("campaign", "speeches", "debates", "interviews"))) %>%
select(-c(length, truth, lies, fpoint, anti_PC)) %>%
pivot_longer(consistency:vulgarism) %>%
mutate(category = ifelse(grepl("territory|vulgarism|origins|common_sense", name),
 "Belong", "Self")) %>%
group_by(year, speaker, setting, diversity, status, party, category) %>%
summarise(total = sum(value)) %>%
dplyr::distinct()
US_model_total <- plm(total ~ status + category + setting + party,
 data = US_mod, model = "within", index = c("year"))
BR_model_total <- plm(total ~ status + category + setting + party,
 data = BR_mod, model = "within", index = c("year"))
US_model_div <- plm(diversity ~ status + category + setting + party,
 data = US_mod, model = "within", index = c("year"))
BR_model_div <- plm(diversity ~ status + category + setting + party,
 data = BR_mod, model = "within", index = c("year"))
stargazer(US_model_total, BR_model_total, US_model_div, BR_model_div,
title = "Authenticity Performances by Status, Setting, and Category,
in Brazil and the US - Fixed-Effects by Year",
column.labels = c("US", "Brazil", "US", "Brazil"),
dep.var.labels = c("Total Normalized Frequency", "Diversity Score"))
```
\end{landscape}
````
